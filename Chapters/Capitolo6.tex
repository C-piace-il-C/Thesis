% Chapter 

\chapter{Il progetto} % Main chapter title

\label{Chapter6} % Change X to a consecutive number; for referencing this 
%chapter elsewhere, use \ref{ChapterX}

\lhead{Capitolo 6. \emph{Il progetto}} % Change X to a consecutive number; this 
%is for the header on each page - perhaps a shortened title

%-------------------------------------------------------------------------------
%	SECTION 6.1
%-------------------------------------------------------------------------------
\section{Il Setup della Piattaforma}
Nella prima fase del progetto ci siamo occupati della sistemazione della 
piattaforma e dell'ambiente di lavoro scegliendo ed installando il sistema 
operativo e tutti gli strumenti necessari, e abbiamo selezionato il software di 
riferimento per l'encoder di HEVC.
%-------------------------------------------------------------------------------
%	SECTION 6.1.1
%-------------------------------------------------------------------------------
\subsection{Il Sistema Operativo}
La prima decisione che ha riguardato la piattaforma è stato il sistema 
operativo da installare. Vi sono a disposizione diversi sistemi 
Unix-like\footnote{Reperibili all'indirizzo
http://www.lemaker.org/portal.php?mod=list\&catid=4}, 
dai più personalizzabili (come Gentoo o Arch Linux) a quelli più
 \emph{user-friendly} (come Lubuntu); la nostra scelta è ricaduta su Bananian, 
una distribuzione che deriva da Debian 7, appositamente ottimizzata per il 
Banana Pi, che abbiamo ritenuto essere il giusto compromesso tra usabilità
e assenza di software preinstallato a noi non necessario. \\
Nonostante la possibilità di lavorare senza ambiente grafico, da terminale, 
risparmiando qualche decina di \emph{megabyte} di RAM, inizialmente abbiamo 
deciso di avvalerci di LXDE, un ambiente desktop estremamente leggero, in modo 
da 
velocizzare la maggior parte delle nostre interazioni con il sistema.
\\ \\
Essendo in tre persone a lavorare su una sola piattaforma, abbiamo optato 
per collocare la \emph{board} in un laboratorio dell'università, dotandola
di un sistema di controllo remoto basato su \emph{Virtual Network Computing} 
(VNC), un sistema che utilizza un protocollo \emph{remote framebuffer} (RFB) 
per l'accesso remoto alle interfacce grafiche utente (meglio conosciute come 
GUIs, \emph{Graphical User Interfaces}). Inoltre, 
per facilitare l'accesso ai dati presenti sulle periferiche di memorizzazione, 
abbiamo dotato il Banana Pi di un server \emph{file transfer protocol} (FTP).
\\ \\
Tuttavia, nella fase finale del progetto, l'interfaccia grafica è stata 
abbandonata in modo da permettere una risposta del sistema più immediata e una 
minore allocazione di risorse; è stato dunque possibile disattivare 
l'accelerazione hardware, necessaria in un ambiente grafico, permettendo il 
risparmio di circa 30MB di RAM. Insieme alla GUI è stato accantonato il 
controllo remoto tramite VNC (fortemente dispendioso a causa del suo approccio 
\emph{pixel-based}) a favore di un accesso tramite SSH (\emph{secure shell}), 
più essenziale e meno dispersivo.
%-------------------------------------------------------------------------------
%	SECTION 6.1.2
%-------------------------------------------------------------------------------
\subsection{L'Ambiente di Lavoro}
La scelta del compilatore è stata molto diretta: abbiamo 
optato subito per 
\emph{GNU Compiler Collection} (GCC), sapendo che si tratta del compilatore più 
popolare e affidabile in ambiente Linux, e che è molto raro che sorgano dei 
problemi di compatibilità nel codice. Come suggerisce il nome, GCC è una 
collezione di compilatori per diversi linguaggi, tra cui i noti C, C++, Fortran 
e Java, nonché un progetto \emph{open source}, costantemente testato ed 
aggiornato: 
l'ultima versione stabile ufficiale, GCC 5.2, è stata rilasciata poco prima 
del momento della scrittura. La versione più recente disponibile nel 
\emph{repository} era però la 4.6.3. Abbiamo provato, senza successo, a 
scaricare e compilare le versioni più nuove dal sito di 
GCC\footnote{https://gcc.gnu.org/releases.html}. Cambiando il repository siamo 
poi riusciti ad ottenere la versione 4.9.2.
\\ \\
Le compilazioni sono state fatte con l'ausilio di Make, 
uno strumento 
che permette di automatizzarne il processo attraverso un file 
testuale - il makefile - che memorizza tutte le impostazioni ed i nomi dei file 
necessari per diversi tipi di compilazione, come \emph{debug} e \emph{release}. 
La maggior 
parte dei progetti \emph{open source} contiene un makefile, così come quello 
che 
abbiamo scelto come riferimento. Qualora si abbia l'esigenza di cambiare le 
opzioni di 
compilazione è sufficiente modificare il makefile, altrimenti tutto si traduce 
nel semplice comando da console \verb|make|. Questo tool risulta quindi molto 
utile sia ai normali utenti, che non hanno bisogno di imparare a compilare per 
installare un 
programma fornito come codice sorgente, sia agli sviluppatori, cui 
si evita di scrivere ogni volta 
comandi molto lunghi dove è facile commettere errori.
\\ \\
Per la valutazione delle prestazioni degli encoder da ottimizzare abbiamo 
utilizzato un \emph{software profiler}.
Il \emph{profiling} è l'operazione di eseguire un programma effettuando su di 
esso, in tempo reale, la misurazione di numerosi parametri utili 
all'ottimizzazione quali la frequenza e la durata delle  
funzioni, la ricorrenza di particolari istruzioni o la memoria utilizzata.
Si tratta di un'analisi dinamica, basata cioè sul funzionamento del programma, 
non solo sul suo codice. I risultati che si ottengono sono di conseguenza 
sicuramente più attendibili e completi di quanto si potrebbe ricavare da 
un'analisi statica, come quella che svolge il compilatore all'atto di 
ottimizzare.\\
Inizialmente abbiamo valutato due software comunemente utilizzati per 
il \emph{profiling}: Valgrind e gperftools.
Entrambi \emph{open source}, offrono diversi strumenti per l'analisi dinamica 
di un programma; quelli considerati in questo progetto sono stati Cachegrind e 
Callgrind per quanto riguarda il primo e il \emph{CPU profiler} del secondo. 
Lo scopo principale di Cachegrind è quello di simulare una cache a due livelli 
per fornire, oltre ai parametri comuni di \emph{profiling}, informazioni in 
varia misura corrette circa 
i \emph{cache miss}. Callgrind aggiunge a queste funzionalità quella, per noi 
fondamentale, di registrare uno storico di tutte le chiamate tra le funzioni. 
In questo modo è più facile avere un'idea della logica del programma, o almeno 
del ruolo di una funzione, valutando da chi è maggiormente chiamata, di quali 
altre funzioni si serve e in che misura.
%-------------------------------------------------------------------------------
%	SECTION 6.1.3
%-------------------------------------------------------------------------------
\subsection{Il Software di Riferimento}
Inizialmente, tre software di encoding sono stati individuati come possibili
candidati per il progetto:
\begin{itemize}
	\item f265
	\item HM (HEVC Test Model)
	\item x265
\end{itemize}
Il primo è stato subito scartato non appena è stato chiaro che il sorgente non 
è compatibile con la piattaforma in nostro possesso (il codice è stato scritto 
unicamente per architettura x86).\\
x265 ha mostrato già in partenza ottime performance riuscendo a 
codificare una sequenza in formato CIF a 1.52 fps, nonostante la versione per 
ARM fosse completamente priva delle funzioni in Assembly presenti per le altre 
architetture.\\
HM, infine, nuovamente privo di codice Assembly e scritto in C++ generico, si è 
rivelato notevolmente più lento di x265 (0.05 fps). Analizzando velocemente i 
sorgenti 
ci siamo resi conto che, coerentemente con le prestazioni osservate, il codice 
di HM è decisamente più chiaro e comprensibile di quello di x265, che 
evidentemente è già carico di parecchie ottimizzazioni. Abbiamo quindi pensato 
che 
lavorare con HM potesse essere, didatticamente parlando, la scelta migliore.
%-------------------------------------------------------------------------------
%	SECTION 6.2
%-------------------------------------------------------------------------------
\section{Individuazione dei moduli H.265}
La legge che l'informatico ed ingegnere statunitense Gene Myron Amdahl presentò 
ad una conferenza nel 
1967\footnote{https://en.wikipedia.org/wiki/Amdahl's\_law}, nota come legge di 
Amdahl (discussa in maggiore dettaglio nella sezione 
\ref{sect-multi}), afferma che il beneficio di un miglioramento operato su un 
sistema non è quantificabile in termini assoluti e va pesato secondo la misura 
con 
cui la parte migliorata influisce sul rendimento finale del sistema. \\
Con la sua legge, Amdahl ha espresso un principio fondamentale nel 
contesto della progettazione di architetture hardware ma universalmente valido, 
e riassunto nella nota frase ``\emph{make the common case fast}''. Il 
significato in questo caso è che, constatata la limitatezza delle risorse a 
disposizione, 
conviene concentrasi sulle parti che influiscono maggiormente 
sulle performance del software, i \emph{common case}.
\\ \\
In quest'ottica abbiamo adoperato il \emph{profiler} Valgrind per trovare le 
funzioni più pesanti dell'encoder HM. Nello specifico, abbiamo utilizzato lo 
strumento Callgrind attraverso il comando seguente. \\
\begin{lstlisting}[breaklines]
valgrind --tool=callgrind TAppEncoderStatic -c 
/home/cpc/ssd/hm_cfg/highway.cfg -c 
/home/cpc/ssd/hm_cfg/PBBB_intra12.cfg
\end{lstlisting}
La prima parte del comando è ovviamente quella che esegue Valgrind specificando 
lo strumento di interesse, Callgrind; la seconda parte, quella che inizia con 
\verb|TAppEncoderStatic|, è il comando con cui normalmente si apre l'encoder 
HM, che è stato precedentemente compilato in \emph{debug} per il 
\emph{profiling}. \\
Al termine del suo lavoro Callgrind genera un file testuale, di default 
denominato \verb|callgrind.out| /*$<$- controllalo*/, contenente tutti i 
risultati 
del \emph{profiling}, anche se in un formato poco \emph{human-friendly}. 
Per analizzare i risultati abbiamo quindi utilizzato il software 
KCacheGrind\footnote{http://kcachegrind.sourceforge.net/html/Home.html}, una 
GUI per la visualizzazione grafica di questo tipo di dati. \\
La tabella che segue mostra le funzioni più influenti nel ciclo di codifica 
della sequenza di test \verb|highway_cif.yuv|.
\\ //INSERISCI TABELLA DI EXCEL
\\ //INSERISCI GRAFICO A TORTA DEI MODULI
%-------------------------------------------------------------------------------
%	SECTION 6.3
%-------------------------------------------------------------------------------
\section{Le Sequenze Video}
Le sequenze campione di tipo \emph{raw} (letteralmente \emph{grezzo}, ovvero 
non compresso) 
trovate in rete per 
eseguire le prove di encoding sono disponibili in diverse risoluzioni. La 
tabella \ref{tabel-resolutions} mostra quelle relative agli standard più comuni.

	\begin{table}[h!]
		\centering
	\begin{tabular}{|l|c|l|}
		\hline
		Standard & Risoluzione & Pixel \\ \hline \hline \hline
		QCIF & $176\times144$ & $25344$ \\ \hline
		CIF & $352\times288$ & $101376$ \\ \hline
		4CIF & $704\times576$ & $405504$ \\ \hline
		720p & $1280\times720$ & $921600$ \\ \hline
		1080p & $1920\times1080$ & $2073600$ \\ \hline
		2K & $2048\times1080$ & $2211840$ \\ \hline
		4K & $4096\times2160$ & $8847360$ \\ \hline
	\end{tabular}
	\caption{Risoluzioni comuni.}
	\label{tabel-resolutions}
	\end{table}
Per quanto riguarda il formato, tuttavia, 
abbiamo riscontrato una situazione completamente diversa: tutte le sequenze che 
abbiamo reperito sono nel formato y4m, mentre generalmente i software di 
encoding, HM compreso, richiedono un ingresso yuv.\\
Per far chiarezza, il termine yuv non fa riferimento ad un vero e proprio 
formato di sequenze video, ma allo spazio dei colori in cui sono codificati i 
frame che compongono la sequenza. In origine il termine indicava una codifica 
analogica del colore per trasmissioni televisive, mentre YCrCb, come discusso 
nella sezione -ref-, descrive la codifica digitale del colore. Oggi, yuv è 
utilizzato per quelle sequenze video i cui colori sono rappresentati in YCrCb.
In sostanza un file con estensione yuv contiene semplicemente il contenuto 
binario dei frame, uno dopo l'altro, senza altre informazioni. \`E compito 
dell'utilizzatore specificare il formato di subsampling e la risoluzione 
corretti.\\
Il formto y4m, acronimo per YUV4MPEG2, differisce leggermente dai file yuv in 
quanto inizia con un header dalla dimensione variabile che contiene parametri 
come larghezza ed altezza dei frame, subsampling e il numero di fps. Inoltre, 
ogni frame inizia con i $5$ byte che compongono la scritta ``FRAME'' seguiti 
dal byte 0x0A ($10$).\\
Non riuscendo a trovare convertitori per Windows o per Linux ad eccezione di 
ffmpeg, che però ci dava alcuni problemi, e data l'estrema semplicità del 
formato y4m, abbiamo deciso di scrivere un programmino in C per eseguire la 
conversione.\\
Molto semplicemente, il programma cerca le prime due occorrenze della stringa   
``FRAME0x0A'' e calcola il numero di byte che le divide, coincidente con la 
dimensione dei frame. Conoscendo la posizione del primo frame all'interno del 
file y4m e la sua lunghezza in byte, è possibile trovare con un semplice 
calcolo la posizione di tutti gli altri frame per copiarli, uno ad uno, nel 
file di destinazione.
Il programma intero è disponibile 
online\footnote{https://github.com/C-piace-il-C/Y4M2YUV}, mentre qui di seguito 
è presente un estratto che mostra la funzione principale.
\begin{center}
\lstinputlisting[language=C,caption=]{Codes/Y4M2YUV.c}
\end{center}
%-------------------------------------------------------------------------------
%	SECTION 6.4
%-------------------------------------------------------------------------------
\section{Strategie di ottimizzazione}
Ottimizzazione del software è un termine generico che può avere diversi 
significati, ma fondamentalmente si tratta di apportare delle modifiche al 
codice per ottenere dei benefici, e dunque la determinante è lo scopo. \`E 
pertanto di 
primaria importanza chiarire che 
questo lavoro è stato svolto con l'intenzione di velocizzare un programma su 
di una piattaforma specifica. Effetti collaterali tipici e tollerati possono 
essere, di conseguenza, la comparsa di codice dipendente dall'architettura, 
vale a dire non funzionante su sistemi incompatibili come potrebbe essere un 
comune 
personal computer x86, e l'utilizzo di più risorse - principalmente memoria, 
sia volatile sia di massa. \\
Oltre all'obiettivo, è anche importante individuare la tipologia delle 
ottimizzazioni 
che abbiamo applicato. Le ottimizzazioni del software possono 
rientrare, in prima istanza, in due 
categorie: quelle che migliorano l'algoritmo e quelle che migliorano il codice. 
\\La prima categoria contiene senz'altro quelle più intelligenti ed 
interessanti, nonché quelle che andrebbero ponderate per prime. L'esempio già 
fatto della trasformata veloce di Fourier rientra proprio in questa categoria. 
Si tratta, in essenza, di migliorare l'algoritmo, non la sua implementazione.
Questo tipo di ottimizzazione porta tipicamente maggiori benefici ed ha 
l'enorme pregio di migliorare automaticamente qualunque ragionevole 
implementazione.\\
Le ottimizzazioni della seconda categoria sono solitamente più semplici e 
banali, tanto che la tendenza degli ultimi anni è quella di delegarle al 
computer per favorire la semplicità di programmazione, come nei linguaggi di 
più alto livello. Queste ottimizzazioni possono consistere in una gestione 
migliore delle risorse disponibili, come nel caso della parallelizzazione 
(sfruttare tutti i core) o nell'impiego di hardware dedicato.
Non cambia quindi tanto ciò che si fa, o algoritmo, quanto il modo di 
svolgerlo.\\
Le ottimizzazioni affrontate in questo lavoro appartengono per ovvi motivi alla 
seconda categoria.
%-----------------------------------
%       SUBSECTION 6.4.1
%-----------------------------------
\subsection{Opzioni di Compilazione}
Per prima cosa abbiamo dedicato del tempo allo studio delle opzioni di 
compilazione fornite da GCC (\emph{GNU Compiler Collection}) al fine di partire 
da una ``base stabile" da ottimizzare.\\
Particolare attenzione è stata dedicata ai \emph{flag} dedicati al 
miglioramento delle performance ed a quelli specifici per ARM.\\
\\
Senza alcuna opzione di compilazione espressa l'obiettivo del compilatore è 
quello di ridurre il più possibile il costo della compilazione e di rendere al 
contempo praticabile il \emph{debug} del programma. Per rendere possibile il 
//debug ciò è necessario in primo luogo che ogni \emph{statement} sia 
indipendente: è possibile fermare l'esecuzione in qualsiasi punto utilizzando 
un \emph{breakpoint} al fine di assegnare a piacere valori alle variabili e/o 
di modificare il \emph{program counter}, ottenendo i risultati attesi dal 
codice.\\
\\
Il compilatore ottimizza il codice basandosi sulla conoscenza che ha del 
programma. Non tutte le ottimizzazioni sono controllabili direttamente via 
\emph{flag}.\\
\\
Passiamo ora ad una breve descrizione delle opzioni utilizzate e dei loro 
effetti sull'eseguibile generato.

Famiglia `-O': opzioni dedicate all'ottimizzazione delle performance e/o della 
dimensione del compilato. La `O' è un diminutivo di ``Optimize".\\
Si distinguono vari livelli di ottimizzazione messi a disposizione dal 
compilatore GCC:
\begin{itemize}
\item \verb|-O0|\\
Opzione predefinita: riduce il tempo di compilazione cercando di dare la 
migliore esperienza di \emph{debug} possibile.
\item \verb|-O / -O1|\\
Abilita tutte le opzioni specificate da \verb|-O0|.\\
Il compilatore cerca di ridurre la dimensione del compilato ed il tempo di 
esecuzione utilizzando \emph{flag} che non peggiorano drasticamente il tempo 
di compilazione.
\item \verb|-O2|\\
Abilita tutte le opzioni specificate da \verb|-O / -O1|.\\
Vengono eseguite tutte le ottimizzazioni che non coinvolgono un 
\emph{trade-off} spazio-velocità. Rispetto al precedente migliora le 
prestazioni allungando il tempo di compilazione.
\item \verb|-Os|\\
Abilita tutte le opzioni specificate da \verb|-O2| che tipicamente non 
aumentano la dimensione dell'eseguibile. Vengono eseguite tutte le 
ottimizzazioni a favore dello spazio occupato dal compilato. La `s' è un 
diminutivo di ``size".
\item \verb|-O3|\\
Abilita tutte le opzioni specificate da \verb|-O2|.\\
Vengono eseguite tutte le ottimizzazioni a favore della velocità di esecuzione. 
Il tempo di compilazione aumenta così come lo spazio occupato dall'eseguibile 
generato. E' il massimo livello di ottimizzazione possibile insieme ad 
\verb|-Ofast|.
\item \verb|-Ofast|\\
Abilita tutte le opzioni specificate da \verb|-O3|.\\
Ignora l'adesione rigorosa allo standard abilitando \verb|-ffast-math|.
\item \verb|-Og|\\
Ottimizza l'esperienza di \emph{debug} abilitando tutte le opzioni che non 
interferiscono con quest'ultimo.
\end{itemize}

Opzioni di ottimizzazione indipendenti dall'hardware:

\begin{itemize}
\item \verb|-ftree-vectorize|\\
Abilita la vettorizzazione dei \emph{tree}.
// Che cos'è un tree?\\
Il compilatore cerca di riorganizzare dati in vettori permettendo così 
l'utilizzo di istruzioni SIMD (\emph{Single Instruction Multiple Data}) al fine 
di migliorare il tempo di esecuzione del codice.\\
Essa abilita inoltre \verb|-ftree-loop-vectorize| e 
\verb|-ftree-slp-vectorize|, che abilitano rispettivamente la vettorizzazione 
dei \emph{loop} e dei \emph{basic block}.
\item \verb|-finline-functions|\\
Considera tutte le funzioni come candidate per un possibile \emph{inlining}, 
anche quelle che non sono dichiarate esplicitamente come \verb|inline|.\\
Il compilatore decide attraverso un calcolo euristico di effettuare o no 
l'\emph{inlining} della funzione. 
\item \verb|-funswitch-loops|\\
Abilitata automaticamente con l'opzione \verb|-O3|.\\
Sposta i \emph{branch} con condizioni che non dipendono dal \emph{loop} al di 
fuori di quest'ultimo, duplicandolo su entrambi i \emph{branch} e modificandolo 
tenendo conto del risultato della condizione.
\item \verb|-funroll-loops|\\
Abilita l'\emph{unrolling} dei \emph{loop} per i quali è possibile determinare 
il numero di iterazioni a \emph{compile time}.
// Aggiungere -fwhole-program?
\end{itemize}
Opzioni di ottimizzazione specifiche per l'hardware ARM:
\begin{itemize}
\item \verb|-march=|\emph{name}\\
Specifica il nome dell'architettura ARM di destinazione.\\
Questo parametro viene utilizzato da GCC per determinare che tipo di istruzioni 
possono essere emesse quando viene generato il codice assembly relativo al 
programma.
\item \verb|-mtune=|\emph{name}\\
Specifica il nome del processore ARM per il quale GCC deve ottimizzare il 
codice. Su alcune implementazioni possono essere ricavate prestazioni migliori 
specificando questa opzione.
\item \verb|-mfpu=|\emph{name}\\
Specifica quale hardware (o emulazione hardware) \emph{floating-point} è 
disponibile sul dispositivo.\\
Quest'opzione è \underline{necessaria} per poter utilizzare le varie SIMD (in 
questo caso NEON) messe a disposizione dall'architettura ARM.
\item \verb|-mfloat-abi=|\emph{name}\\
Specifica quale ABI (o \emph{Application Binary Interface}) utilizzare per le 
operazioni \emph{floating-point}. // Che cos'è un ABI? \\
Quest'opzione è \underline{necessaria} per poter utilizzare le varie SIMD (in 
questo caso NEON) messe a disposizione dall'architettura ARM.
\end{itemize}

Opzioni del linguaggio e del \emph{debug}.

\begin{itemize}
\item \verb|-fopt-info-|\emph{options}\\
Mostra un \emph{log} contenente informazioni su ciò che è o non è stato 
ottimizzato.
\item \verb|-std=|\emph{name}\\
Determina quale standard utilizzare per il linguaggio C da compilare.
\item \verb|-pthread|\\
Abilita il supporto al \emph{multithreading} con la libreria \emph{phtreads}.
\end{itemize}

Queste opzioni sono state testate modificando il file \verb|makefile.base|, 
contenuto nella cartella \verb|/build/linux/common/|. Di seguito le linee 
dall'originale:\\

\begin{lstlisting}[language=make]
# default cpp flags for all configurations
CPPFLAGS          = -fPIC $(DEFS) -I$(CURDIR)/$(INC_DIR) $(USER_INC_DIRS) -Wall
                    -Wshadow -Wno-sign-compare -Werror
# debug cpp flags
DEBUG_CPPFLAGS    = -g -D_DEBUG
# release cpp
RELEASE_CPPFLAGS  = -O3 -Wuninitialized
\end{lstlisting}

Per prima cosa è stato cambiato il livello di ottimizzazione da \verb|-O3| a 
\verb|-Ofast| per quanto riguarda i \verb|RELEASE_CPPFLAGS|.\\
Questa modifica è stata effettuata al fine di migliorare le \emph{performance} 
sulle operazioni matematiche, è stato inoltre verificato che il comportamento 
del programma non fosse cambiato (\verb|-ffast-math| può portare a risultati 
sbagliati in certe configurazioni).\\
Assieme a suddetta modifica è stato cambiato il \emph{flag} \verb|-g| in 
\verb|-Og| per quanto riguarda i \verb|DEBUG_CPPFLAGS|.\\
Questo al fine di velocizzare il più possibile il \emph{debug} 
dell'applicazione, particolarmente lento utilizzando \verb|-g|.\\
Sono state poi inserite tutte le opzioni relative all'hardware ARM in 
\verb|CPPFLAGS|, i \emph{flag} condivisi da tutte le configurazioni.\\
Nello specifico sono state inserite le seguenti voci: \verb|-march=armv7-a|, 
\verb|-mtune=cortex-a7|, \verb|-mfpu=neon|, \verb|-mfloat-abi=softfp|.\\
Subito dopo questa modifica è stato ancora aggiunta ai \verb|RELEASE_CPPFLAGS| 
l'opzione \verb|-ftree-vectorize|.\\
\\
Prima di iniziare la modifica vera e propria del codice è stata effettuata 
un'analisi mediante l'utilizzo di \verb|-fopt-info-vec-optimized| al fine di 
sapere cosa fosse stato già vettorizzato automaticamente da GCC. Questo ci ha 
permesso di focalizzarci maggiormente sulle funzioni onerose non modificate.\\
\\
E' stato inoltre deciso di rendere \emph{multithread} il programma.\\
E' stato in primo luogo provato il \emph{multithreading} offerto dallo standard 
C++11, aggiungendo quindi \verb|-std=c++11| alle opzioni esistenti.\\
Avendo però notato un degrado delle performance generali in \emph{single 
thread}, sì è deciso di utilizzare la libreria \emph{pthreads} e quindi di 
sostituire il \emph{flag} \verb|-std=c++11| con \verb|-pthread|.

Il file \verb|makefile.base| finale è quindi il seguente:\\

\begin{lstlisting}[language=make]
# default cpp flags for all configurations
CPPFLAGS          = -fPIC $(DEFS) -I$(CURDIR)/$(INC_DIR) $(USER_INC_DIRS) -Wall 
                    -Wshadow -Wno-sign-compare -Werror -march=armv7-a 
                    -mtune=cortex-a7 -mfpu=neon -mfloat-abi=softfp -pthread
# debug cpp flags
DEBUG_CPPFLAGS    = -Og -D_DEBUG
# release cpp
RELEASE_CPPFLAGS  = -Ofast -Wuninitialized -ftree-vectorize
\end{lstlisting}


// Tentativi con -fwhole-program.\\
// gcc-4.7 non vettorizzava ARM, gcc-4.9 sì.\\
// Risultati\\
%-----------------------------------
%       SUBSECTION 6.4.2
%-----------------------------------
\subsection{Assembly}
// IMPOSTA FONT CONSOLAS PER I LISTATI \newline
// INGRANDISCI IL FONT DI TESTO E LISTATI \newline
Un'altra ottimizzazione sperimentata inizialmente è stata
 la stesura di funzioni in Assembly nel tentativo di ottimizzare alcune parti 
 di codice delle funzioni più onerose di HM.
Le principali caratteristiche del linguaggio Assembly ARM che velocizzano un 
programma sono le istruzioni condizionali e il \emph{barrel
 	 shifter}. \newline
Le istruzioni condizionali sono normali istruzioni la cui esecuzione dipende
dal valore di determinati \emph{flag}. In questo modo è possibile evitare
parecchi branch condizionali che rallentano il codice perché rompono la
\emph{pipeline}.\newline
Il \emph{barrel shifter} è un'unità che compie una pre-elaborazione di uno dei 
due operandi di un'istruzione attraverso una normale operazione di shift dei 
bit. \newline
//SPIGA PERCHE IL BARREL SHIFTER VELOCIZZA (NON AGGIUNGE TEMPO ESECUZIONE)
//AGGIUNGI IMMAGINE BARREL SHIFTER \newline

\par Per esempio, la funzione matematica $\text{clamp}(x) = 
\max(a,\min(x,b))$, assente dalla libreria standard, viene implementata da 
\verb+filter+ in questo modo:
\lstinputlisting[language=C,caption=]{Codes/cclamp.c}
Questo codice viene tradotto in \verb|-Ofast| in una dozzina di istruzioni con 
due \emph{compare}. Notando che nel codice di HM \verb|minVal| vale sempre 0, è 
possibile introdurre un'ottimizzazione che sfrutta il barrel shifter. \newline
Segue il confronto tra l'estratto del codice Assembly generato da GCC (a 
sinistra) e quello da noi scritto per eseguire clamp.
// ALLINEA VERTICALMENTE I DUE LISTATI

\lstset{style=cstyle}
\begin{center}
  \begin{tabularx}{\textwidth}{ X | c }
  	\hline
    \lstinputlisting[caption=]{Codes/armgccclamp.s}
    \xdef\tempwidth{\thelstlisting\linewidth} &
    \lstinputlisting[stepnumber=0,caption=]{Codes/armclamp.s} \\
    \hline
  \end{tabularx}
\end{center}
Per maggiore chiarezza il codice generato da GCC è stato commentato riga per 
riga e viene discusso a seguire. \newline
Le prime due linee caricano 0 e \verb|val|, che inizia a partire da 4 byte dalla
 posizione puntata da \verb|SP| (Stack Pointer), rispettivamente nei registri
  \verb|r2| e \verb|r3|.\newline La terza linea esegue l'operazione
   \verb|r3 - r2| aggiornando i flag contenuti in \verb|CPSR| (Current Program 
Status Register).\newline L'istruzione \verb|itt lt| abilita la condizione 
\verb|lt| (lower than) per le successive due istruzioni, che verranno quindi 
eseguite solo se \verb|r3| $<$ \verb|r2|. Ciò si riflette sull'\emph{opcode}
delle due istruzioni successive, che eredita il suffisso \verb|lt|. Queste
istruzioni mettono 0 in \verb|r3| e lo salvano in \verb|val|. \newline
Le restanti istruzioni eseguono il secondo \verb|if| in maniera analoga.\newline
Nel nostro codice la terza linea compendia quello che in C sarebbe 
\verb|if(r3 < 0) r3 = 0|. Il suffisso \verb|s| specifica che l'istruzione 
aggiorna anche il 
registro \verb|CPSR|, così, se il risultato è positivo (i.e. \verb|r3| $>$ 0), 
si procede con le istruzioni 5 e 6 che sostituiscono \verb|maxVal| a \verb|r3| 
nel caso in cui \verb|r3| $>$ \verb|maxVal|.
\par Nonostante gli esiti positivi dell'ottimizzazione in fase di
testing, dopo l'implementazione effettiva all'interno di HM la performance 
dell'encoder è calata, come mostra la tabella.
\begin{table}[h!]
	\centering
  \begin{tabular}{l | l | l}
    & ASM & C \\ \hline
    $8\cdot10^9$ clamp & $7065.6$ (ms) & $8072.7$ (ms) \\
    $72$ frame \verb|highway_cif.yuv| & $1493.614$ (s) &  $1408.426$ (s) \\
  \end{tabular}
\end{table}
Le righe della tabella mostrano rispettivamente una media di $10$ prove
fatte con un 
codice di test 
compilato in \verb|-Ofast| /*INSERISCI IL CODICE IN APPENDICE*/ e di $5$ prove 
con il software HM eseguito sui primi $72$ 
frame 
della sequenza \verb|highway_cif.yuv|.\newline
Il motivo di tale discrepanza può essere visto 
nel fatto che, vicino alla funzione Assembly inline, GCC è costretto ad 
inserire un prologo ed un epilogo in cui salva e carica lo stato del programma, 
mentre nella serie di test ciò non è necessario.\newline
Una possibile soluzione consiste nel riscrivere almeno parzialmente la funzione 
\verb|filter| 
in Assembly per predisporre correttamente i dati, eventualmente
ottimizzando anche altre parti del codice, ma è un'operazione che al momento 
esula dalle nostre competenze.

%-----------------------------------
%       SUBSECTION 6.4.3
%-----------------------------------
\subsection{Intrinsic NEON}

Tra le varie ottimizzazioni che implicavano la modifica del codice, è stato 
dato largo spazio alle SIMD di ARM: le cosiddette NEON.\\
La tecnologia NEON permette di accelerare le operazioni matematiche più usate 
permettendo di effettuare più calcoli in parallelo.\\
Architettura introdotta con ARMv7, utilizza 32 registri a 64-bit interpretati 
come ``vettori di elementi''. I registri possono essere accoppiati in modo da 
lavorare con vettori a 128 bit, ognuno di essi può essere utilizzato come:

\begin{itemize}
  \item Un vettore con 2 elementi da 64 bit ciascuno.
  \item Un vettore con 4 elementi da 32 bit ciascuno.
  \item Un vettore con 8 elementi da 16 bit ciascuno.
  \item Un vettore con 16 elementi da 8 bit ciascuno.
\end{itemize}

Tutti gli elementi (\emph{lanes}) di un vettore devono essere dello stesso 
tipo, nello specifico possono essere:

\begin{itemize}
  \item Un intero \emph{signed} oppure \emph{unsigned}.
  \item Un \emph{floating-point} a singola precisione: \verb|float|.
\end{itemize}

Ogni istruzione NEON effettua la \textbf{stessa} operazione su tutti i 
\emph{lane}.\\

Per poter utilizzare le \emph{intrinsic} NEON in un contesto C (ma anche C++) è 
necessario includere la libreria \verb|arm_neon.h| ed aggiungere le opzioni di 
compilazione relative all'hardware \emph{floating-point}: \verb|-mfpu=neon| e 
\verb|-mfloat-abi=softfp|. Una spiegazione più approfondita dei sopracitati 
\emph{flag} è stata data nella sezione dedicata alle opzioni di compilazione.\\

Avendo alla mano i dati sulle funzioni più onerose in termini di istruzioni, 
facendo un controllo incrociato con \emph{log} generato dall'opzione 
\verb|-fopt-info-vec-optimized|, si è osservato che tutte le la quasi totalità 
di quelle dedicate alle SAD (\emph{Sum of Absolute Differences}) non era stata 
automaticamente vettorizzata.\\

Il lavoro con le \emph{intrinsic} è iniziato da lì. Verranno spiegati i 
passaggi a partire dal codice originale di \verb|xGetSAD8|, il procedimento è 
stato riprodotto in modo analogo per tutte le altre funzioni.\\

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  Distortion uiSum = 0;
  
  for ( ; iRows != 0; iRows -= iSubStep)
  {
    uiSum += abs(piOrg[0] - piCur[0]);
    uiSum += abs(piOrg[1] - piCur[1]);
    uiSum += abs(piOrg[2] - piCur[2]);
    uiSum += abs(piOrg[3] - piCur[3]);
    uiSum += abs(piOrg[4] - piCur[4]);
    uiSum += abs(piOrg[5] - piCur[5]);
    uiSum += abs(piOrg[6] - piCur[6]);
    uiSum += abs(piOrg[7] - piCur[7]);
    
    piOrg += iStrideOrg;
    piCur += iStrideCur;
  }
\end{lstlisting}

Dove \verb|Distortion| è del tipo \verb|uint32_t| (rappresentante un intero 
\emph{unsigned} a 32-bit), mentre \verb|piOrg| e \verb|piCur| sono del tipo 
\verb|int16_t *| (rappresentanti un \emph{array} di interi \emph{signed} a 
16-bit).\\

Il codice si presta molto bene ad essere vettorizzato utilizzando le SIMD NEON:

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  // Set all v_iSum lanes to 0
  int16x8_t v_iSum = vdupq_n_s16(0);
  
  for ( ; iRows != 0; iRows -= iSubStep)
  {
    // Load 8 elements into vector
    int16x8_t v_piOrg = vld1q_s16(piOrg);
    int16x8_t v_piCur = vld1q_s16(piCur);
    
    // v_iSum += |v_piOrg - v_piCur|
    v_iSum = vabaq_s16(v_iSum0, v_piOrg, v_piCur);
  
    piOrg += iStrideOrg;
    piCur += iStrideCur;
  }
  
  // Sum all lanes in v_iSum
  Distortion uiSum = (Distortion)(
      vgetq_lane_s16(v_iSum, 0) + vgetq_lane_s16(v_iSum, 1) +
      vgetq_lane_s16(v_iSum, 2) + vgetq_lane_s16(v_iSum, 3) +
      vgetq_lane_s16(v_iSum, 4) + vgetq_lane_s16(v_iSum, 5) +
      vgetq_lane_s16(v_iSum, 6) + vgetq_lane_s16(v_iSum, 7)
    );
\end{lstlisting}

Le \emph{intrinsic} utilizzate sono le seguenti:

\begin{itemize}
  \item \verb|vdupq_n_s16(int16_t value)| (\emph{\textbf{V}ector 
    \textbf{Dup}licate})\\
      Carica in tutti gli elementi del vettore il valore espresso da 
      \verb|value|.\\
      La \verb|q| indica che l'operazione viene effettuata a 128 bit invece dei 
      canonici 64, mentre \verb|s16| (\emph{\textbf{S}igned \textbf{16}}) 
      indica il tipo dato di ogni elemento.
  \item \verb|vld1q_s16(int16_t const * ptr)| (\emph{\textbf{V}ector 
    \textbf{L}oa\textbf{d}})\\
      Carica tutti gli elementi del vettore a partire da un \emph{array} dello 
      stesso tipo presente in memoria.
  \item \verb|vabaq_s16(int16x8_t a, int16x8_t b, int16x8_t c)| 
    (\emph{\textbf{V}ector \textbf{Ab}solute Difference and 
    \textbf{A}ccumulate})\\
      Ritorna il valore assoluto della differenza tra \verb|b| e \verb|c| 
      aggiungendoci il valore di \verb|a|.
  \item \verb| vgetq_lane_s16(int16x8_t vec, int lane)| (\emph{\textbf{V}ector 
    \textbf{Get} \textbf{Lane}})\\
      Ritorna il valore dell'elemento \verb|lane|-\emph{esimo} del vettore 
      \verb|vec|.      
\end{itemize}

E' stato osservato come sia più veloce l'utilizzo di \verb|vgetq_lane_s16| su 
ogni componente di \verb|v_iSum| al fine di ricavare la somma di tutte le 
componenti del vettore. Degno di nota il fatto che a partire da ARMv8 sia stata 
inserita un'\emph{intrinsic} dedicata a questa operazione.\\

Più spinosa è stata la vettorizzazione delle funzioni dedicate al calcolo della 
trasformata Walsh–Hadamard su blocchi di immagine, già implementata nella sua 
versione \emph{fast}. Questa categoria di funzioni è stata vettorizzata solo 
parzialmente ma, essendo le più onerose, il miglioramento prestazionale è stato 
significativo.\\

Di seguito un estratto della versione originale di \verb|xCalcHADs4x4|, presa 
come esempio:

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  Int k;
  Distortion satd = 0;
  
  TCoeff diff[16], m[16], d[16];
  
  for (k = 0; k < 16; k += 4)
  {
    diff[k+0] = piOrg[0] - piCur[0];
    diff[k+1] = piOrg[1] - piCur[1];
    diff[k+2] = piOrg[2] - piCur[2];
    diff[k+3] = piOrg[3] - piCur[3];
  
    piCur += iStrideCur;
    piOrg += iStrideOrg;
  }
  
  m[ 0] = diff[ 0] + diff[12];
  m[ 1] = diff[ 1] + diff[13];
  m[ 2] = diff[ 2] + diff[14];
  m[ 3] = diff[ 3] + diff[15];
  
  m[ 4] = diff[ 4] + diff[ 8];
  m[ 5] = diff[ 5] + diff[ 9];
  m[ 6] = diff[ 6] + diff[10];
  m[ 7] = diff[ 7] + diff[11];
  
  m[ 8] = diff[ 4] - diff[ 8];
  m[ 9] = diff[ 5] - diff[ 9];
  m[10] = diff[ 6] - diff[10];
  m[11] = diff[ 7] - diff[11];
  
  m[12] = diff[ 0] - diff[12];
  m[13] = diff[ 1] - diff[13];
  m[14] = diff[ 2] - diff[14];
  m[15] = diff[ 3] - diff[15];
  
  d[ 0] = m[ 0] + m[ 4];
  d[ 1] = m[ 1] + m[ 5];
  d[ 2] = m[ 2] + m[ 6];
  d[ 3] = m[ 3] + m[ 7];
  d[ 4] = m[ 8] + m[12];
  d[ 5] = m[ 9] + m[13];
  d[ 6] = m[10] + m[14];
  d[ 7] = m[11] + m[15];
  d[ 8] = m[ 0] - m[ 4];
  d[ 9] = m[ 1] - m[ 5];
  d[10] = m[ 2] - m[ 6];
  d[11] = m[ 3] - m[ 7];
  d[12] = m[12] - m[ 8];
  d[13] = m[13] - m[ 9];
  d[14] = m[14] - m[10];
  d[15] = m[15] - m[11];
  
  /* ... */
\end{lstlisting}

Dove \verb|Int| e \verb|TCoeff| sono entrambi del tipo \verb|int32_t| 
(rappresentanti un intero \emph{signed} a 32-bit).\\

In questo caso è stata mostrata solo la porzione di codice che ha subito 
modifiche per un migliore raffronto.\\

Viene ora presentata la versione vettorizzata.

%TODO usare style
\begin{lstlisting}[language=C]
  Int k;
  Distortion satd = 0;
  
  TCoeff m[16], d[16];
  int32x4_t v_diff[4], v_m[4], v_d[4];
  
  for (k = 0; k < 4; k++)
  {
    int16x4_t v_piOrg = vld1_s16(piOrg);
    int16x4_t v_piCur = vld1_s16(piCur);
    
    v_diff[k] = vsubl_s16(v_piOrg, v_piCur);
  
    piCur += iStrideCur;
    piOrg += iStrideOrg;
  }
  
  v_m[0] = vaddq_s32(v_diff[0], v_diff[3]);
  v_m[1] = vaddq_s32(v_diff[1], v_diff[2]);
  v_m[2] = vsubq_s32(v_diff[1], v_diff[2]);
  v_m[3] = vsubq_s32(v_diff[0], v_diff[3]);
  
  // Store 'v_m' in 'm'
  vst1q_s32(m     , v_m[0]);
  vst1q_s32(m + 4 , v_m[1]);
  vst1q_s32(m + 8 , v_m[2]);
  vst1q_s32(m + 12, v_m[3]);
  
  v_d[0] = vaddq_s32(v_m[0], v_m[1]);
  v_d[1] = vaddq_s32(v_m[2], v_m[3]);
  v_d[2] = vsubq_s32(v_m[0], v_m[1]);
  v_d[3] = vsubq_s32(v_m[3], v_m[2]);
  
  // Store 'v_d' in 'd'
  vst1q_s32(d     , v_d[0]);
  vst1q_s32(d + 4 , v_d[1]);
  vst1q_s32(d + 8 , v_d[2]);
  vst1q_s32(d + 12, v_d[3]);
  
  /* ... */
\end{lstlisting}

Oltre alle precedenti \emph{intrinsic} vengono utilizzate le seguenti:

\begin{itemize}
  \item \verb|vsubl_s16(int16x4_t a, int16x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Sub}tract \textbf{L}ong})\\
      Calcola le differenze a 16-bit tra i vettori \verb|a| e \verb|b|, il 
      risultato è salvato in un vettore a 32-bit.
  \item \verb|vaddq_s32(int32x4_t a, int32x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Add}})\\
      Calcola la somma a 32-bit tra i vettori \verb|a| e \verb|b|.
  \item \verb|vaddq_s32(int32x4_t a, int32x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Sub}tract})\\
      Calcola la differenza a 32-bit tra i vettori \verb|a| e \verb|b|.
  \item \verb|vst1q_s32(int32_t * ptr, int32x4_t val)| (\emph{\textbf{V}ector 
    \textbf{St}ore})\\
      Salva il vettore \verb|val| nell'\emph{array} di destinazione \verb|ptr|.
\end{itemize}

%-----------------------------------
%       SUBSECTION 6.4.4
%-----------------------------------
\subsection{Switch}

%TODO rivedere questa frase
Tra le ottimizzazioni possibili è stato dedicato del tempo alla sostituzione 
degli \verb|if| a valori costanti con equivalenti \verb|switch|.
In questi casi, infatti, il compilatore genera una \emph{jump table} basandosi 
sui valori che può assumere la variabile utilizzata per lo \verb|switch|.\\

Avendo identificato tra le funzioni più onerose \verb|filter|, verranno ora 
citati due spezzoni di codice da essa:

%TODO aggiungere style
\begin{lstlisting}
  c[0] = coeff[0];
  c[1] = coeff[1];
  
  if (N >= 4)
  {
    c[2] = coeff[2];
    c[3] = coeff[3];
  }
  if (N >= 6)
  {
    c[4] = coeff[4];
    c[5] = coeff[5];
  }
  if (N == 8)
  {
    c[6] = coeff[6];
    c[7] = coeff[7];
  }
  
  /* ... */
  
  sum    = src[col + 0 * cStride] * c[0];
  sum   += src[col + 1 * cStride] * c[1];
  
  if (N >= 4)
  {
    sum += src[col + 2 * cStride] * c[2];
    sum += src[col + 3 * cStride] * c[3];
  }
  if (N >= 6)
  {
    sum += src[col + 4 * cStride] * c[4];
    sum += src[col + 5 * cStride] * c[5];
  }
  if (N == 8)
  {
    sum += src[col + 6 * cStride] * c[6];
    sum += src[col + 7 * cStride] * c[7];
  }
\end{lstlisting}

Analizzando il codice è stato appurato che la variabile \verb|N| può assumere 
valori tra $4$ ed $8$. E' possibile quindi sostituire i blocchi di \verb|if| 
con dei più efficienti \verb|switch|. 
%Avendo cura di porre il caso più ricorrente per primo (\verb|N = 8|), è 
%%%possibile rimpiazzare tutte le istruzioni condizionali con una somma ed un 
%%%%\emph{jump} relativo.

%TODO style
\begin{lstlisting}
switch (N)
{
  case 8:
    c[7] = coeff[7];
    c[6] = coeff[6];
  case 7:
  case 6:
    c[5] = coeff[5];
    c[4] = coeff[4];
  case 5:
  case 4:
    c[3] = coeff[3];
    c[2] = coeff[2];
  default:
    c[1] = coeff[1];
    c[0] = coeff[0];
    break;
}

/* ... */

switch (N)
{
  case 8:
    sum += src[col + 7 * cStride] * c[7];
    sum += src[col + 6 * cStride] * c[6];
  case 7:
  case 6:
    sum += src[col + 5 * cStride] * c[5];
    sum += src[col + 4 * cStride] * c[4];
  case 5:
  case 4:
    sum += src[col + 3 * cStride] * c[3];
    sum += src[col + 2 * cStride] * c[2];
  default:
    sum += src[col + 1 * cStride] * c[1];
    sum += src[col + 0 * cStride] * c[0];
    break;
}
\end{lstlisting}

Riorganizzando il codice come sopra è possibile incrementare le prestazioni: 
viene effettuato un solo \emph{jump} all'istruzione corretta. Le seguenti sono 
già riordinate in modo tale da velocizzare il più possibile l'esecuzione del 
codice.\\

Questa modifica ha, ovviamente, un bassissimo impatto sulle prestazioni 
complessive del codice. E' stata implementata esclusivamente a scopo didattico.

%-----------------------------------
%       SUBSECTION 6.4.5
%-----------------------------------
\subsection{Attributi}
Oltre alle opzioni di compilazione, GCC mette a disposizione un insieme di   
attributi per descrivere esplicitamente il comportamento di funzioni (ma anche 
variabili e tipi), spesso con il fine di migliorare la qualità 
dell'ottimizzazione.\\
Gli attributi possono essere aggiunti con la keyword 
\verb|__attribute__((a1,a2,...))| inserita nella dichiarazione di una funzione 
tra il tipo di ritorno ed il nome.\\
Segue una lista con gli attributi presi in considerazione 
per l'ottimizzazione, anche se in seguito non sono stati sfruttati tutti.
 
\begin{itemize}
	\item\verb|hot|\\
	L'attributo \verb|hot| serve per comunicare che la funzione è un ``punto 
	caldo'', ovvero una funzione che si assume impegnare una 
	porzione considerevole del tempo di esecuzione del programma.
	Queste funzioni vengono ottimizzate più ``aggressivamente'', tipicamente a 
	spese della memoria, e vengono collocate insieme in una sezione speciale 
	per soddisfare maggiormente il principio della località, utile a diminuire 
	i \emph{cache miss}.\\
	\verb|hot| è stato applicato a \verb|filter|, alle funzioni 
	\verb|xCalcHADs| e \verb|xGetSAD|.
	
	\item\verb|always_inline|\\
	Ci sono casi in cui l'estensione \verb|__inline| viene ignorata dal 
	compilatore. Alcuni esempi sono la compilazione senza ottimizzazioni, le 
	funzioni che superano una certa soglia massima di lunghezza, misurata come 
	numero di istruzioni, oppure le funzioni la cui percentuale di espansione 
	causata da inline 
	$\nicefrac{\text{lunghezza}_\text{f}}{\text{lunghezza}_\text{i}}$ 
	 oltre una determinata soglia.
	Questo attributo permette di rendere inline una funzione ignorando tali 
	restrizioni. Nella pratica però è stato preferito \verb|__inline|, sia 
	perché come già detto le compilazioni vengono fatte in \verb|-Ofast|, sia 
	perché, durante le prove, \verb|always_inline| ha sempre generato errori di 
	compilazione. \verb|__inline| è stato applicato a \verb|filterCopy|, 
	\verb|filter|, a 
	tutte le \verb|xCalcHADs| e le \verb|xGetSAD|.

	\item\verb|pure|\\
	L'attributo \verb|pure| comunica al compilatore che la funzione non produce 
	effetti se non sul valore restituito, e che vengono considerati solo gli 
	argomenti passati alla funzione e le variabili globali. Queste funzioni 
	subiscono ottimizzazioni come la Common Subexpression Elimination (CSE) e 
	di loop. Queste ottimizzazioni si basano sul fatto 
	che, essendo \verb|pure|, la funzione non ha effetti collaterali sul 
	programma e 
	può quindi essere richiamata meno volte di quanto accade esplicitamente nel 
	codice, o, addiriturra, in posizioni diverse, a patto di non modificare i 
	parametri in ingresso. \verb|pure| è stato applicato a tutte le 
	funzioni \verb|xCalcHADs|
	
	\item\verb|const|\\
	L'attributo \verb|const| è simile a \verb|pure| ma più restrittivo, visto 
	che descrive una funzione che non accede nemmeno a variabili globali.
	Dato che una funzione \verb|const| può avere effetto solo sul valore 
	restituito e può accedere solo ai suoi argomenti, generalmente non ha senso 
	che la funzione restituisca \verb|void| o che i parametri siano dei 
	puntatori, a meno che non ci si aspetti che vengano modificati. 
	\verb|const| è stato applicato alle funzioni \verb|xGetSAD|.
	
	\item\verb|cold|\\
	L'attributo \verb|cold| viene utilizzato per dichiarare che una funzione 
	non occupa parti temporalmente rilevanti nell'esecuzione complessiva del 
	programma. Per questo motivo, GCC può evitare le ottimizzazioni più dure 
	risparmiando risorse che possono essere utilizzate per altre funzioni. 
	Anche questo attributo non è stato utilizzato in quanto, nonostante tutte 
	le ottimizzazioni implementate, il software non raggiunge mai i $300$ B di 
	memoria occupata (neanche $\nicefrac{1}{3}$ di quella disponibile) 
	\\ //AGGIUNGI CONFRONTO DIMENSIONE ESEGUIBILE opt/non opt.
\end{itemize}

L'utilizzo degli attributi, però, non ha avuto alcun riscontro sulle 
performance, che in media sono rimaste invariate. \\
// MOSTRA ASM DEI CAMBIAMENTI \\
// FAI IPOTESI
%-----------------------------------
%       SUBSECTION 6.4.6
%-----------------------------------
\label{sect-multi}\subsection{Multithread}
Nonostante l'evoluzione di software ed hardware sia ormai da anni concentrata 
sulla parallelizzazione, HM non è stato pensato né scritto per tale 
caratteristica. Ne segue che una delle ottimizzazioni più doverose è stata il 
multithreading.
\par Teoricamente, il limite massimo raggiungibile dallo \emph{speedup} $S$ 
servendosi 
di $N$ thread paralleli è proprio $N$, ottenuto secondo la legge di Amdahl
$$S = \frac{1}{(1-P)+\frac{P}{N}}$$
essendo $P$ la frazione di codice parallelizzabile, dove $1$ corrisponde al 
$100\%$. Ponendo infatti $P = 1$ si ricava $S = N$. Ovviamente uno speedup 
esattamente di $N$ non si può mai ottenere, sia perché risulta molto difficile 
rendere 
$P$ precisamente $1$, sia perché la legge non tiene conto dell'overhead di 
controllo associato alla gestione della sincronizzazione dei thread, che 
tipicamente passa anche per il sistema operativo, rallentando ulteriormente.
\par Le strategie di parallelizzazione sono molteplici. Nell'ambito di questo 
lavoro ne abbiamo considerate due relativamente complementari, che aprono
una buona prospettiva per la discussione dei fattori che normalmente 
caratterizzano il software parallelo. Le tecniche esaminate sono basate sulla 
parallelizzazione dei CTU (\emph{Wavefront Parallel Processing}, WPP) e dei 
frame della sequenza.

\paragraph*{WPP} Questa tecnica consiste nella parallelizzazione della 
predizione e 
dell'entropy coding a livello di CTU. Come è noto, però, i CTU non sono 
indipendenti tra loro, e dunque le operazioni che li riguardano non possono 
essere parallelizzate senza i controlli adeguati. In particolare, la predizione 
e l'entropy coding di un CTU necessita delle informazioni relative ai blocchi 
vicini a sinistra, alto-sinitra, alto, alto-destra /*spiega perché*/. Questo 
significa che i thread devono essere in grado di attendere finché le 
informazioni necessarie al loro lavoro non diventano disponibili. \\
Una possibile realizzazione di questa tecnica consiste nell'utilizzo di una 
tavola condivisa tra i thread, per esempio attraverso un riferimento globale, 
con le informazioni circa lo stato di completamento dei vari CTU. Il codice dei 
singo thread si occupa quindi di consultare la tabella per decidere se operare 
sui prossimi CTB oppure attendere /*meglio sleep o nop?*/.\\
Un'altra complicazione sta nella gestione dell'ordine di esecuzione dei blocchi 
per evitare che più thread lavorino sullo stesso CTU. La soluzione più semplice 
è assegnare ad ogni thread una riga diversa servendosi di \verb|threadid|, un 
parametro normalmente impostato durante la creazione di un thread che ne 
rappresenta un identificativo unico e incrementale. Un generico thread lavora 
sulla riga $\verb|threadid| + r \cdot N$, dove $r$, inizialmente a $0$, viene 
incrementato di $1$ ogni volta che si terminata una riga, e $N$ è il numero di 
thread in parallelo.  \\
La percentuale di codice parallelizzabile non è il $100\%$ dato che, nonostante 
la parte predittiva e l'entropy encoding rappresentino buona parte della 
codifica H265, non ne costituiscono comunque la totalità.
\\ \\
La seconda tecnica di parallelizzazione consiste nella 
suddivisione della sequenza di partenza in più parti indipendenti, intendendo 
con ``parti'' blocchi di frame contigui.\\
Se $N$ è il numero di core a disposizione, 
si vuole suddividere la sequenza in $N$ parti omogenee (grandi uguale). I frame 
chiave sono quelli predetti interamente intra, visto che rompono ogni 
legame di dipendenza con quelli precedenti, e possono servire da riferimento 
per la suddivisione.\\
Successivamente è possibile far partire $N$ thread di encoding 
indipendenti, ciascuno su una parte diversa della sequenza. In seguito, data la 
struttura 
pacchettizzata dell'output di HEVC, è possibile ricomporre l'intera 
sequenza semplicemente congiungendo nel corretto ordine le $N$ stringhe binarie 
prodotte. \\
Come evidente, questa tecnica annulla ogni tipo di \emph{overhead} di 
sincronizzazione e gestione dei thread e permette di coprire il $100\%$ del 
codice per la parallelizzazione. Il difetto in questo caso non sta nel codice 
ma nei dati, perché per raggiungere lo speedup massimale è necessario che i 
frame intra siano disposti secondo una certa logica. Tuttavia, per garantire 
bunoi livelli di parallelismo, è sufficiente che il valore di 
\verb|intraperiod| (numero di frame tra due intra) sia sufficientemente più 
basso del numero complessivo di frame della sequenza da codificare. \\
Naturalmente anche in condizioni perfette non si può raggiungere uno speedup di 
$N$ per via delle procedure di avvio dei thread e di
unione delle sequenze binarie, che penalizzano la codifica 
rispetto alla versione \emph{singlethread}. La buona 
notizia è che tali operazioni sono trascurabili già con sequenze corte, e lo 
sono sempre più, in proporzione, con l'aumentare del numero di frame.\\
Infine è bene osservare che questa tecnica non può essere applicata 
nei casi di encoding in tempo reale, anche se ciò diventa secondario se si nota 
che HM di per sé non ammette tale opzione.
\\ \\
Segue uno schema che riassume le due tecniche discusse.
\\ // DIMINUISCI LA LUNGHEZZA DELLA PRIMA COLONNA
\begin{center}
	\begin{tabularx}{\textwidth}{>{}X|>{}X|>{}X}
		
		    & Pros & Cons \\ \hline
		WPP & 
		    \begin{itemize}
		    	\item Più adatto ai casi reali
			\end{itemize}
			&
			\begin{itemize}
				\item Alto \emph{overhead}
				\item Difficoltà implementativa
				\item $P < 1$
			\end{itemize} \\ \hline
		SS &
		   \begin{itemize}
			   	\item Nessun \emph{overhead}
			   	\item Semplicità implementativa
			   	\item $P = 1$
		   \end{itemize}
		   &
		   \begin{itemize}
		   	    \item Preferibile \verb|intraperiod| basso
		   \end{itemize}
	\end{tabularx}
\end{center}
Come prima cosa abbiamo implementato la seconda tecnica, quella più 
semplice e verosimilmente la più efficiente, data la struttura fissata del GOP, 
riuscendo ad ottenere un quasi ideale fattore di speedup $S \approx 2$. In 
seguito abbiamo provato anche la prima, purtroppo senza successo dato l'elevato 
numero di modifiche, anche strutturali, che presentava un codice non 
predisposto all'esecuzione parallela.
\\Per programmare in \emph{multithreading} in C abbiamo utilizzato la libreria 
\verb|pthread| includendo \verb|pthread.h| e aggiungendo l'opzione di 
compilazione \verb|-pthread|.\\
Per avviare un thread è necessario costruirne la funzione principale seguendo 
il prototipo \verb|void *(*start_routine)(void*)|. Il parametro di ingresso di 
tipo \verb|void*| può essere utilizzato per fornire al thread dei dati 
preliminari, come \verb|threadid|, ma anche degli indirizzi di 
memoria dove il thread può registrare eventuali risultati o comunicazioni verso 
il resto del programma, oppure leggere eventuali comandi o dati dinamici 
provenienti da altri thread. \\
Scritta la routine, è possibile richiamare \verb|pthread_create| per creare e 
far partire il thread. \verb|pthread_join| può essere utilizzata per bloccare 
l'esecuzione del thread chiamante finché non è terminata quella di un altro 
thread specificato, utile per la sincronizzazione. Per terminare l'esecuzione 
di un thread, si può richiamare \verb|pthread_exit|, che ha lo stesso effetto 
di un semplice \verb|return(ptr)|.\\
Segue il codice scritto per l'implementazione.\\
\begin{center}
\lstinputlisting[language=C,caption=]{Codes/multithreading.c}
\end{center}
La parte di main rimossa per brevità è poco interessante e consiste nella 
lettura dei parametri dai file di configurazione per la costruzione dei valori 
di input per il secondo thread, \verb|argc| e \verb|argv|.
\begin{center}
	\begin{tabular}{l | l | l}
		& Multithread & Singlethread \\
		\hline
		$72$ frame \verb|highway_cif.yuv| & $741.560$ (s) & $1408.426$ (s)
	\end{tabular}
\end{center}
La tabella mostra la media dei risultati ottenuti eseguendo $5$ volte 
l'encoding dei primi $72$ frame del file di prova \verb|highway_cif.yuv| con il 
software HM compilato in \verb|-Ofast| nella sua versione \emph{singlethread} e 
\emph{multithread}. Il fattore di speedup è di circa $1.9$. Si noti comunque 
che i valori mostrati sono una media in cui, per motivi di tempo, il numero di 
prove non è molto alto, mentre la variabilità è elevata (abbiamo registrato un 
massimo di $20$ secondi di differenza tra due cicli di encoding della stessa 
sequenza con le medesime configurazioni).
