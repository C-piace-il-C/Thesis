% Chapter 

\chapter{Il progetto} % Main chapter title

\label{Chapter6} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Capitolo 6. \emph{Il progetto}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%-------------------------------------------------------------------------------
%	SECTION 1
%-------------------------------------------------------------------------------

\section{Il setup della piattaforma}
La prima decisione che ha riguardato la piattaforma è stato il sistema 
operativo da installare. Vi sono a disposizione diversi sistemi 
Unix-like\footnote{http://www.lemaker.org/portal.php?mod=list\&catid=4}, 
dai più personalizzabili (come Gentoo o Arch Linux) a quelli più
 \emph{user-friendly} (come Lubuntu); la nostra scelta è ricaduta su Bananian, 
una distribuzione che deriva da Debian 7, appositamente ottimizzata per il 
Banana Pi, che abbiamo ritenuto essere il giusto compromesso tra usabilità
e assenza di software preinstallato a noi non necessario. \\
Nonostante la possibilità di lavorare senza ambiente grafico, da terminale, 
risparmiando qualche decina di \emph{megabyte} di RAM, inizialmente abbiamo 
deciso di avvalerci di LXDE, un ambiente desktop estremamente leggero, in modo da 
velocizzare la maggior parte delle nostre interazioni con il sistema. \\
\\ \\
Essendo tre persone a lavorare su una sola piattaforma, abbiamo optato 
per collocare la \emph{board} in un laboratorio dell'università, dotandola
di un sistema di controllo remoto basato su \emph{virtual network computing} 
(VNC), un sistema che utilizza un protocollo \emph{remote framebuffer} (RBF) 
per l'accesso remoto alle interfacce grafiche utente (meglio conosciute come 
\textbf{GUI}s, \textbf{G}raphical \textbf{U}ser \textbf{I}nterfaces). Inoltre, 
per facilitare l'accesso ai dati presenti sulle periferiche di memorizzazione, 
abbiamo dotato il Banana Pi di un server \emph{file transfer protocol} (FTP).
\\ \\ 
Tuttavia, nella fase finale del progetto, l'intefaccia grafica è stata 
abbandonata in modo da permettere una risposta del sistema più immediata e una 
minore allocazione di risorse; è stato dunque possibile disattivare 
l'accelerazione hardware, necessaria in un ambiente grafico, permettendo il 
risparmio di circa 30MB di RAM. Insieme alla GUI è stata accantonato il 
controllo remoto tramite VNC (fortemente dispendioso a causa del suo approccio 
\emph{pixel-based}) a favore di un accesso tramite SSH (\emph{secure shell}), 
più essenziale e meno dispersivo.

%-------------------------------------------------------------------------------
%	SECTION 2
%-------------------------------------------------------------------------------

\section{I tool per la compilazione}

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Il compilatore GCC}

%-----------------------------------
%       SUBSECTION 2
%-----------------------------------

\subsection{Il tool make}

%-------------------------------------------------------------------------------
%	SECTION 3
%-------------------------------------------------------------------------------

\section{I tool per valutare le prestazioni}
Per la valutazione delle prestazioni degli encoder da ottimizzare, è stato 
fatto uso di due strumenti software:
\begin{itemize}
\item Valgrind
\item gperftools
\end{itemize}
Entrambi \emph{opensource}, offrono diversi strumenti per l'analisi dinamica 
di un software; quelli utilizzati in questo progetto sono stati
\emph{Cachegrind} e \emph{Callgrind} per quanto riguarda il primo e il 
\emph{CPU profiler} del secondo.
%-------------------------------------------------------------------------------
%	SECTION 3
%-------------------------------------------------------------------------------

\section{I software di encoding presi in considerazione}
Inizialmente, tre software di encoding sono stati individuati come possibili
candidati per il progetto:
\begin{itemize}
\item f265
\item HM (\textbf{H}EVC Test \textbf{M}odel)
\item x265
\end{itemize}
Il primo è stato subito scartato non appena è stato chiaro che il sorgente non 
è compatibile con la piattaforma in nostro possesso (il codice è stato scritto 
unicamente per architettura x86).
I rimanenti due sono stati oggetto di 
%-------------------------------------------------------------------------------
%	SECTION 4
%-------------------------------------------------------------------------------

\section{Test preliminari}

%-------------------------------------------------------------------------------
%	SECTION 5
%-------------------------------------------------------------------------------

\section{Individuazione dei moduli H.265}

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Il tool KCacheGrind / QCacheGrind}

%-------------------------------------------------------------------------------
%	SECTION 6
%-------------------------------------------------------------------------------

\section{Strategie di ottimizzazione}
Ottimizzazione del software è un termine generico che può avere diversi 
significati. Fondamentalmente si tratta di apportare delle modifiche al codice 
per ottenere dei benefici, e dunque la determinante è lo scopo. \`E pertanto di 
primaria importanza chiarire subito che 
questo lavoro è stato svolto con l'intenzione di velocizzare un programma su 
di una piattaforma specifica. Effetti collaterali tipici e accettati possono 
essere, di conseguenza, la comparsa di codice dipendente dall'architettura, 
vale a dire non funzionante su sistemi incompatibili come potrebbe essere un 
comune 
personal computer x86, e l'utilizzo di più risorse - principalmente memoria, 
sia volatile che di massa. \\
Oltre all'obiettivo, è anche importante individuare la tipologia delle 
ottimizzazioni 
che abbiamo applicato. Le ottimizzazioni del software possono 
rientrare, in prima istanza, in due 
categorie: quelle che migliorano l'algoritmo e quelle che migliorano il codice. 
\\La prima categoria contiene senz'altro quelle più intelligenti ed 
interressanti, nonché quelle che andrebbero ponderate per prime. L'esempio già 
fatto della trasformata veloce di Fourier rientra proprio in questa categoria. 
Si tratta, in essenza, di migliorare l'algoritmo, non la sua implementazione.
Questo tipo di ottimizzazione porta tipicamente maggiori benefici ed ha 
l'enorme pregio di migliorare automaticamente qualuqune ragionevole 
implementazione.
\\Le ottimizzazioni della seconda categoria sono solitamente più semplici e 
banali, tanto che la tendenza degli ultimi anni è quella di delegarle al 
computer per favorire la semplicità di programmazione, come nei linguaggi di 
più alto livello. Queste ottimizzazioni possono consistere in una gestione 
migliore delle risorse disponibili, come nel caso della parallelizzazione 
(sfruttare tutti i core) o nell'impiego di hardware dedicato.
Non cambia quindi tanto ciò che si fa, o algoritmo, quanto il modo di 
svolgerlo.\\
Le ottimizzazioni affrontate in questo lavoro appartengono per ovvi motivi alla 
seconda categoria
%vooooleeevi eh, col taccuino

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Opzioni di Compilazione}
Per prima cosa abbiamo dedicato del tempo allo studio delle opzioni di 
compilazione fornite da GCC (\emph{GNU Compiler Collection}) al fine di partire 
da una ``base stabile" da ottimizzare.\\
Particolare attenzione è stata dedicata ai \emph{flag} dedicati al 
miglioramento delle performance ed a quelli specifici per ARM.\\
\\
Senza alcuna opzione di compilazione espressa l'obiettivo del compilatore è 
quello di ridurre il più possibile il costo della compilazione e di rendere al 
contempo praticabile il \emph{debug} del programma. Per rendere possibile il 
//debug ciò è necessario in primo luogo che ogni \emph{statement} sia 
indipendente: è possibile fermare l'esecuzione in qualsiasi punto utilizzando 
un \emph{breakpoint} al fine di assegnare a piacere valori alle variabili e/o 
di modificare il \emph{program counter}, ottenendo i risultati attesi dal 
codice.\\
\\
Il compilatore ottimizza il codice basandosi sulla conoscenza che ha del 
programma. Non tutte le ottimizzazioni sono controllabili direttamente via 
\emph{flag}.\\
\\
Passiamo ora ad una breve descrizione delle opzioni utilizzate e dei loro 
effetti sull'eseguibile generato.

Famiglia `-O': opzioni dedicate all'ottimizzazione delle performance e/o della 
dimensione del compilato. La `O' è un diminutivo di ``Optimize".\\
Si distinguono vari livelli di ottimizzazione messi a disposizione dal 
compilatore GCC:
\begin{itemize}
\item \verb|-O0|\\
Opzione predefinita: riduce il tempo di compilazione cercando di dare la 
migliore esperienza di \emph{debug} possibile.
\item \verb|-O / -O1|\\
Abilita tutte le opzioni specificate da \verb|-O0|.\\
Il compilatore cerca di ridurre la dimensione del compilato ed il tempo di 
esecuzione utilizzando \emph{flag} che non peggiorano drasticamente il tempo 
di compilazione.
\item \verb|-O2|\\
Abilita tutte le opzioni specificate da \verb|-O / -O1|.\\
Vengono eseguite tutte le ottimizzazioni che non coinvolgono un 
\emph{trade-off} spazio-velocità. Rispetto al precedente migliora le 
prestazioni allungando il tempo di compilazione.
\item \verb|-Os|\\
Abilita tutte le opzioni specificate da \verb|-O2| che tipicamente non 
aumentano la dimensione dell'eseguibile. Vengono eseguite tutte le 
ottimizzazioni a favore dello spazio occupato dal compilato. La `s' è un 
diminutivo di ``size".
\item \verb|-O3|\\
Abilita tutte le opzioni specificate da \verb|-O2|.\\
Vengono eseguite tutte le ottimizzazioni a favore della velocità di esecuzione. 
Il tempo di compilazione aumenta così come lo spazio occupato dall'eseguibile 
generato. E' il massimo livello di ottimizzazione possibile insieme ad 
\verb|-Ofast|.
\item \verb|-Ofast|\\
Abilita tutte le opzioni specificate da \verb|-O3|.\\
Ignora l'adesione rigorosa allo standard abilitando \verb|-ffast-math|.
\item \verb|-Og|\\
Ottimizza l'esperienza di \emph{debug} abilitando tutte le opzioni che non 
interferiscono con quest'ultimo.
\end{itemize}

Opzioni di ottimizzazione indipendenti dall'hardware:

\begin{itemize}
\item \verb|-ftree-vectorize|\\
Abilita la vettorizzazione dei \emph{tree}.
// Che cos'è un tree?\\
Il compilatore cerca di riorganizzare dati in vettori permettendo così 
l'utilizzo di istruzioni SIMD (\emph{Single Instruction Multiple Data}) al fine 
di migliorare il tempo di esecuzione del codice.\\
Essa abilita inoltre \verb|-ftree-loop-vectorize| e 
\verb|-ftree-slp-vectorize|, che abilitano rispettivamente la vettorizzazione 
dei \emph{loop} e dei \emph{basic block}.
\item \verb|-finline-functions|\\
Considera tutte le funzioni come candidate per un possibile \emph{inlining}, 
anche quelle che non sono dichiarate esplicitamente come \verb|inline|.\\
Il compilatore decide attraverso un calcolo euristico di effettuare o no 
l'\emph{inlining} della funzione. 
\item \verb|-funswitch-loops|\\
Abilitata automaticamente con l'opzione \verb|-O3|.\\
Sposta i \emph{branch} con condizioni che non dipendono dal \emph{loop} al di 
fuori di quest'ultimo, duplicandolo su entrambi i \emph{branch} e modificandolo 
tenendo conto del risultato della condizione.
\item \verb|-funroll-loops|\\
Abilita l'\emph{unrolling} dei \emph{loop} per i quali è possibile determinare 
il numero di iterazioni a \emph{compile time}.
// Aggiungere -fwhole-program?
\end{itemize}

Opzioni di ottimizzazione specifiche per l'hardware ARM:

\begin{itemize}
\item \verb|-march=|\emph{name}\\
Specifica il nome dell'architettura ARM di destinazione.\\
Questo parametro viene utilizzato da GCC per determinare che tipo di istruzioni 
possono essere emesse quando viene generato il codice assembly relativo al 
programma.
\item \verb|-mtune=|\emph{name}\\
Specifica il nome del processore ARM per il quale GCC deve ottimizzare il 
codice. Su alcune implementazioni possono essere ricavate prestazioni migliori 
specificando questa opzione.
\item \verb|-mfpu=|\emph{name}\\
Specifica quale hardware (o emulazione hardware) \emph{floating-point} è 
disponibile sul dispositivo.\\
Quest'opzione è \underline{necessaria} per poter utilizzare le varie SIMD (in 
questo caso NEON) messe a disposizione dall'architettura ARM.
\item \verb|-mfloat-abi=|\emph{name}\\
Specifica quale ABI (o \emph{Application Binary Interface}) utilizzare per le 
operazioni \emph{floating-point}. // Che cos'è un ABI? \\
Quest'opzione è \underline{necessaria} per poter utilizzare le varie SIMD (in 
questo caso NEON) messe a disposizione dall'architettura ARM.
\end{itemize}

Opzioni del linguaggio e del \emph{debug}.

\begin{itemize}
\item \verb|-fopt-info-|\emph{options}\\
Mostra un \emph{log} contenente informazioni su ciò che è o non è stato 
ottimizzato.
\item \verb|-std=|\emph{name}\\
Determina quale standard utilizzare per il linguaggio C da compilare.
\item \verb|-pthread|\\
Abilita il supporto al \emph{multithreading} con la libreria \emph{phtreads}.
\end{itemize}

Queste opzioni sono state testate modificando il file \verb|makefile.base|, 
contenuto nella cartella \verb|/build/linux/common/|. Di seguito le linee 
dall'originale:\\

\begin{lstlisting}[language=make]
# default cpp flags for all configurations
CPPFLAGS          = -fPIC $(DEFS) -I$(CURDIR)/$(INC_DIR) $(USER_INC_DIRS) -Wall
                    -Wshadow -Wno-sign-compare -Werror
# debug cpp flags
DEBUG_CPPFLAGS    = -g -D_DEBUG
# release cpp
RELEASE_CPPFLAGS  = -O3 -Wuninitialized
\end{lstlisting}

Per prima cosa è stato cambiato il livello di ottimizzazione da \verb|-O3| a 
\verb|-Ofast| per quanto riguarda i \verb|RELEASE_CPPFLAGS|.\\
Questa modifica è stata effettuata al fine di migliorare le \emph{performance} 
sulle operazioni matematiche, è stato inoltre verificato che il comportamento 
del programma non fosse cambiato (\verb|-ffast-math| può portare a risultati 
sbagliati in certe configurazioni).\\
Assieme a suddetta modifica è stato cambiato il \emph{flag} \verb|-g| in 
\verb|-Og| per quanto riguarda i \verb|DEBUG_CPPFLAGS|.\\
Questo al fine di velocizzare il più possibile il \emph{debug} 
dell'applicazione, particolarmente lento utilizzando \verb|-g|.\\
Sono state poi inserite tutte le opzioni relative all'hardware ARM in 
\verb|CPPFLAGS|, i \emph{flag} condivisi da tutte le configurazioni.\\
Nello specifico sono state inserite le seguenti voci: \verb|-march=armv7-a|, 
\verb|-mtune=cortex-a7|, \verb|-mfpu=neon|, \verb|-mfloat-abi=softfp|.\\
Subito dopo questa modifica è stato ancora aggiunta ai \verb|RELEASE_CPPFLAGS| 
l'opzione \verb|-ftree-vectorize|.\\
\\
Prima di iniziare la modifica vera e propria del codice è stata effettuata 
un'analisi mediante l'utilizzo di \verb|-fopt-info-vec-optimized| al fine di 
sapere cosa fosse stato già vettorizzato automaticamente da GCC. Questo ci ha 
permesso di focalizzarci maggiormente sulle funzioni onerose non modificate.\\
\\
E' stato inoltre deciso di rendere \emph{multithread} il programma.\\
E' stato in primo luogo provato il \emph{multithreading} offerto dallo standard 
C++11, aggiungendo quindi \verb|-std=c++11| alle opzioni esistenti.\\
Avendo però notato un degrado delle performance generali in \emph{single 
thread}, sì è deciso di utilizzare la libreria \emph{pthreads} e quindi di 
sostituire il \emph{flag} \verb|-std=c++11| con \verb|-pthread|.

Il file \verb|makefile.base| finale è quindi il seguente:\\

\begin{lstlisting}[language=make]
# default cpp flags for all configurations
CPPFLAGS          = -fPIC $(DEFS) -I$(CURDIR)/$(INC_DIR) $(USER_INC_DIRS) -Wall 
                    -Wshadow -Wno-sign-compare -Werror -march=armv7-a 
                    -mtune=cortex-a7 -mfpu=neon -mfloat-abi=softfp -pthread
# debug cpp flags
DEBUG_CPPFLAGS    = -Og -D_DEBUG
# release cpp
RELEASE_CPPFLAGS  = -Ofast -Wuninitialized -ftree-vectorize
\end{lstlisting}


// Tentativi con -fwhole-program.\\
// gcc-4.7 non vettorizzava ARM, gcc-4.9 sì.\\
// Risultati\\
%-----------------------------------
%       SUBSECTION 2
%-----------------------------------

\subsection{Assembly}
// IMPOSTA FONT CONSOLAS PER I LISTATI \newline
// INGRANDISCI IL FONT DI TESTO E LISTATI \newline
Un'altra ottimizzazione sperimentata inizialmente è stata
 la stesura di funzioni in Assembly nel tentativo di ottimizzare alcune parti 
 di codice delle funzioni più onerose di HM.
Le principali caratteristiche del linguaggio Assembly ARM che velocizzano un 
programma sono le istruzioni condizionali e il \emph{barrel
 	 shifter}. \newline
Le istruzioni condizionali sono normali istruzioni la cui esecuzione dipende
dal valore di determinati \emph{flag}. In questo modo è possibile evitare
parecchi branch condizionali che rallentano il codice perché rompono la
\emph{pipeline}.\newline
Il \emph{barrel shifter} è un'unità che compie una pre-elaborazione di uno dei 
due operandi di un'istruzione attraverso una normale operazione di shift dei 
bit. \newline
//SPIGA PERCHE IL BARREL SHIFTER VELOCIZZA (NON AGGIUNGE TEMPO ESECUZIONE)
//AGGIUNGI IMMAGINE BARREL SHIFTER \newline

\par Per esempio, la funzione matematica $\text{clamp}(x) = 
\max(a,\min(x,b))$, assente dalla libreria standard, viene implementata da 
\verb+filter+ in questo modo:
\lstinputlisting[language=C,caption=]{Codes/cclamp.c}
Questo codice viene tradotto in \verb|-Ofast| in una dozzina di istruzioni con 
due \emph{compare}. Notando che nel codice di HM \verb|minVal| vale sempre 0, è 
possibile introdurre un'ottimizzazione che sfrutta il barrel shifter. \newline
Segue il confronto tra l'estratto del codice Assembly generato da GCC (a 
sinistra) e quello da noi scritto per eseguire clamp.
// ALLINEA VERTICALMENTE I DUE LISTATI

\lstset{style=cstyle}
\begin{center}
  \begin{tabularx}{\textwidth}{ X | c }
  	\hline
    \lstinputlisting[caption=]{Codes/armgccclamp.s}
    \xdef\tempwidth{\thelstlisting\linewidth} &
    \lstinputlisting[stepnumber=0,caption=]{Codes/armclamp.s} \\
    \hline
  \end{tabularx}
\end{center}
Per maggiore chiarezza il codice generato da GCC è stato commentato riga per 
riga e viene discusso a seguire. \newline
Le prime due linee caricano 0 e \verb|val|, che inizia a partire da 4 byte dalla
 posizione puntata da \verb|SP| (Stack Pointer), rispettivamente nei registri
  \verb|r2| e \verb|r3|.\newline La terza linea esegue l'operazione
   \verb|r3 - r2| aggiornando i flag contenuti in \verb|CPSR| (Current Program 
Status Register).\newline L'istruzione \verb|itt lt| abilita la condizione 
\verb|lt| (lower than) per le successive due istruzioni, che verranno quindi 
eseguite solo se \verb|r3| $<$ \verb|r2|. Ciò si riflette sull'\emph{opcode}
delle due istruzioni successive, che eredita il suffisso \verb|lt|. Queste
istruzioni mettono 0 in \verb|r3| e lo salvano in \verb|val|. \newline
Le restanti istruzioni eseguono il secondo \verb|if| in maniera analoga.\newline
Nel nostro codice la terza linea compendia quello che in C sarebbe 
\verb|if(r3 < 0) r3 = 0|. Il suffisso \verb|s| specifica che l'istruzione 
aggiorna anche il 
registro \verb|CPSR|, così, se il risultato è positivo (i.e. \verb|r3| $>$ 0), 
si procede con le istruzioni 5 e 6 che sostituiscono \verb|maxVal| a \verb|r3| 
nel caso in cui \verb|r3| $>$ \verb|maxVal|.
\par Nonostante gli esiti positivi dell'ottimizzazione in fase di
testing, dopo l'implementazione effettiva all'interno di HM la performance 
dell'encoder è calata, come mostra la tabella.
\begin{center}
  \begin{tabular}{l | l | l}
    & ASM & C \\ \hline
    $8\cdot10^9$ clamp & $7065.6$ (ms) & $8072.7$ (ms) \\
    $72$ frame \verb|highway_cif.yuv| & $1493.6142$ (s) &  $1408.4262$ (s) \\
  \end{tabular}
\end{center}
Le righe della tabella mostrano rispettivamente una media di $10$ prove
fatte con un 
codice di test 
compilato in \verb|-Ofast| /*INSERISCI IL CODICE IN APPENDICE*/ e di $5$ prove 
con il software HM eseguito sui primi $72$ 
frame 
della sequenza \verb|highway_cif.yuv|.\newline
Il motivo di tale discrepanza può essere visto 
nel fatto che, vicino alla funzione Assembly inline, GCC è costretto ad 
inserire un prologo ed un epilogo in cui salva e carica lo stato del programma, 
mentre nella serie di test ciò non è necessario.\newline
Una possibile soluzione consiste nel riscrivere almeno parziamente la funzione 
\verb|filter| 
in Assembly per predisporre correttamente i dati, eventualmente
ottimizzando anche altre parti del codice, ma è un'operazione che al momento 
esula dalle nostre competenze.

%-----------------------------------
%       SUBSECTION 3
%-----------------------------------

\subsection{Intrinsic NEON}

Tra le varie ottimizzazioni che implicavano la modifica del codice, è stato 
dato largo spazio alle SIMD di ARM: le cosiddette NEON.\\
La tecnologia NEON permette di accelerare le operazioni matematiche più usate 
permettendo di effettuare più calcoli in parallelo.\\
Architettura introdotta con ARMv7, utilizza 32 registri a 64-bit interpretati 
come ``vettori di elementi''. I registri possono essere accoppiati in modo da 
lavorare con vettori a 128 bit, ognuno di essi può essere utilizzato come:

\begin{itemize}
  \item Un vettore con 2 elementi da 64 bit ciascuno.
  \item Un vettore con 4 elementi da 32 bit ciascuno.
  \item Un vettore con 8 elementi da 16 bit ciascuno.
  \item Un vettore con 16 elementi da 8 bit ciascuno.
\end{itemize}

Tutti gli elementi (\emph{lanes}) di un vettore devono essere dello stesso 
tipo, nello specifico possono essere:

\begin{itemize}
  \item Un intero \emph{signed} oppure \emph{unsigned}.
  \item Un \emph{floating-point} a singola precisione: \verb|float|.
\end{itemize}

Ogni istruzione NEON effettua la \textbf{stessa} operazione su tutti i 
\emph{lane}.\\

Per poter utilizzare le \emph{intrinsic} NEON in un contesto C (ma anche C++) è 
necessario includere la libreria \verb|arm_neon.h| ed aggiungere le opzioni di 
compilazione relative all'hardware \emph{floating-point}: \verb|-mfpu=neon| e 
\verb|-mfloat-abi=softfp|. Una spiegazione più approfondita dei sopracitati 
\emph{flag} è stata data nella sezione dedicata alle opzioni di compilazione.\\

Avendo alla mano i dati sulle funzioni più onerose in termini di istruzioni, 
facendo un controllo incrociato con \emph{log} generato dall'opzione 
\verb|-fopt-info-vec-optimized|, si è osservato che tutte le la quasi totalità 
di quelle dedicate alla SAD (\emph{Sum of Absolute Differences}) era stata 
automaticamente vettorizzata.\\

Il lavoro con le \emph{intrinsic} è iniziato da lì. Verranno spiegati i 
passaggi a partire dal codice originale di \verb|xGetSAD8|, il procedimento è 
stato riprodotto in modo analogo per tutte le altre funzioni.\\

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  Distortion uiSum = 0;
  
  for ( ; iRows != 0; iRows -= iSubStep)
  {
    uiSum += abs(piOrg[0] - piCur[0]);
    uiSum += abs(piOrg[1] - piCur[1]);
    uiSum += abs(piOrg[2] - piCur[2]);
    uiSum += abs(piOrg[3] - piCur[3]);
    uiSum += abs(piOrg[4] - piCur[4]);
    uiSum += abs(piOrg[5] - piCur[5]);
    uiSum += abs(piOrg[6] - piCur[6]);
    uiSum += abs(piOrg[7] - piCur[7]);
    
    piOrg += iStrideOrg;
    piCur += iStrideCur;
  }
\end{lstlisting}

Dove \verb|Distortion| è del tipo \verb|uint32_t| (rappresentante un intero 
\emph{unsigned} a 32-bit), mentre \verb|piOrg| e \verb|piCur| sono del tipo 
\verb|int16_t *| (rappresentanti un \emph{array} di interi \emph{signed} a 
16-bit).\\

Il codice si presta molto bene ad essere vettorizzato utilizzando le SIMD NEON:

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  // Set all v_iSum lanes to 0
  int16x8_t v_iSum = vdupq_n_s16(0);
  
  for ( ; iRows != 0; iRows -= iSubStep)
  {
    // Load 8 elements into vector
    int16x8_t v_piOrg = vld1q_s16(piOrg);
    int16x8_t v_piCur = vld1q_s16(piCur);
    
    // v_iSum += |v_piOrg - v_piCur|
    v_iSum = vabaq_s16(v_iSum0, v_piOrg, v_piCur);
  
    piOrg += iStrideOrg;
    piCur += iStrideCur;
  }
  
  // Sum all lanes in v_iSum
  Distortion uiSum = (Distortion)(
      vgetq_lane_s16(v_iSum, 0) + vgetq_lane_s16(v_iSum, 1) +
      vgetq_lane_s16(v_iSum, 2) + vgetq_lane_s16(v_iSum, 3) +
      vgetq_lane_s16(v_iSum, 4) + vgetq_lane_s16(v_iSum, 5) +
      vgetq_lane_s16(v_iSum, 6) + vgetq_lane_s16(v_iSum, 7)
    );
\end{lstlisting}

Le \emph{intrinsic} utilizzate sono le seguenti:

\begin{itemize}
  \item \verb|vdupq_n_s16(int16_t value)| (\emph{\textbf{V}ector 
    \textbf{Dup}licate})\\
      Carica in tutti gli elementi del vettore il valore espresso da 
      \verb|value|.\\
      La \verb|q| indica che l'operazione viene effettuata a 128 bit invece dei 
      canonici 64, mentre \verb|s16| (\emph{\textbf{S}igned \textbf{16}}) 
      indica il tipo dato di ogni elemento.
  \item \verb|vld1q_s16(int16_t const * ptr)| (\emph{\textbf{V}ector 
    \textbf{L}oa\textbf{d}})\\
      Carica tutti gli elementi del vettore a partire da un \emph{array} dello 
      stesso tipo presente in memoria.
  \item \verb|vabaq_s16(int16x8_t a, int16x8_t b, int16x8_t c)| 
    (\emph{\textbf{V}ector \textbf{Ab}solute Difference and 
    \textbf{A}ccumulate})\\
      Ritorna il valore assoluto della differenza tra \verb|b| e \verb|c| 
      aggiungendoci il valore di \verb|a|.
  \item \verb| vgetq_lane_s16(int16x8_t vec, int lane)| (\emph{\textbf{V}ector 
    \textbf{Get} \textbf{Lane}})\\
      Ritorna il valore dell'elemento \verb|lane|-\emph{esimo} del vettore 
      \verb|vec|.      
\end{itemize}

E' stato osservato come sia più veloce l'utilizzo di \verb|vgetq_lane_s16| su 
ogni componente di \verb|v_iSum| al fine di ricavare la somma di tutte le 
componenti del vettore. Degno di nota il fatto che a partire da ARMv8 sia stata 
inserita un'\emph{intrinsic} dedicata a questa operazione.\\

Più spinosa è stata la vettorizzazione delle funzioni dedicate al calcolo della 
trasformata Walsh–Hadamard su blocchi di immagine, già implementata nella sua 
versione \emph{fast}. Questa categoria di funzioni è stata vettorizzata solo 
parzialmente ma, essendo le più onerose, il miglioramento prestazionale è stato 
significativo.\\

Di seguito un estratto della versione originale di \verb|xCalcHADs4x4|, presa 
come esempio:

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  Int k;
  Distortion satd = 0;
  
  TCoeff diff[16], m[16], d[16];
  
  for (k = 0; k < 16; k += 4)
  {
    diff[k+0] = piOrg[0] - piCur[0];
    diff[k+1] = piOrg[1] - piCur[1];
    diff[k+2] = piOrg[2] - piCur[2];
    diff[k+3] = piOrg[3] - piCur[3];
  
    piCur += iStrideCur;
    piOrg += iStrideOrg;
  }
  
  m[ 0] = diff[ 0] + diff[12];
  m[ 1] = diff[ 1] + diff[13];
  m[ 2] = diff[ 2] + diff[14];
  m[ 3] = diff[ 3] + diff[15];
  
  m[ 4] = diff[ 4] + diff[ 8];
  m[ 5] = diff[ 5] + diff[ 9];
  m[ 6] = diff[ 6] + diff[10];
  m[ 7] = diff[ 7] + diff[11];
  
  m[ 8] = diff[ 4] - diff[ 8];
  m[ 9] = diff[ 5] - diff[ 9];
  m[10] = diff[ 6] - diff[10];
  m[11] = diff[ 7] - diff[11];
  
  m[12] = diff[ 0] - diff[12];
  m[13] = diff[ 1] - diff[13];
  m[14] = diff[ 2] - diff[14];
  m[15] = diff[ 3] - diff[15];
  
  d[ 0] = m[ 0] + m[ 4];
  d[ 1] = m[ 1] + m[ 5];
  d[ 2] = m[ 2] + m[ 6];
  d[ 3] = m[ 3] + m[ 7];
  d[ 4] = m[ 8] + m[12];
  d[ 5] = m[ 9] + m[13];
  d[ 6] = m[10] + m[14];
  d[ 7] = m[11] + m[15];
  d[ 8] = m[ 0] - m[ 4];
  d[ 9] = m[ 1] - m[ 5];
  d[10] = m[ 2] - m[ 6];
  d[11] = m[ 3] - m[ 7];
  d[12] = m[12] - m[ 8];
  d[13] = m[13] - m[ 9];
  d[14] = m[14] - m[10];
  d[15] = m[15] - m[11];
  
  /* ... */
\end{lstlisting}

Dove \verb|Int| e \verb|TCoeff| sono entrambi del tipo \verb|int32_t| 
(rappresentanti un intero \emph{signed} a 32-bit).\\

In questo caso è stata mostrata solo la porzione di codice che ha subito 
modifiche per un migliore raffronto.\\

Viene ora presentata la versione vettorizzata.

%TODO usare style
\begin{lstlisting}[language=C]
  Int k;
  Distortion satd = 0;
  
  TCoeff m[16], d[16];
  int32x4_t v_diff[4], v_m[4], v_d[4];
  
  for (k = 0; k < 4; k++)
  {
    int16x4_t v_piOrg = vld1_s16(piOrg);
    int16x4_t v_piCur = vld1_s16(piCur);
    
    v_diff[k] = vsubl_s16(v_piOrg, v_piCur);
  
    piCur += iStrideCur;
    piOrg += iStrideOrg;
  }
  
  v_m[0] = vaddq_s32(v_diff[0], v_diff[3]);
  v_m[1] = vaddq_s32(v_diff[1], v_diff[2]);
  v_m[2] = vsubq_s32(v_diff[1], v_diff[2]);
  v_m[3] = vsubq_s32(v_diff[0], v_diff[3]);
  
  // Store 'v_m' in 'm'
  vst1q_s32(m     , v_m[0]);
  vst1q_s32(m + 4 , v_m[1]);
  vst1q_s32(m + 8 , v_m[2]);
  vst1q_s32(m + 12, v_m[3]);
  
  v_d[0] = vaddq_s32(v_m[0], v_m[1]);
  v_d[1] = vaddq_s32(v_m[2], v_m[3]);
  v_d[2] = vsubq_s32(v_m[0], v_m[1]);
  v_d[3] = vsubq_s32(v_m[3], v_m[2]);
  
  // Store 'v_d' in 'd'
  vst1q_s32(d     , v_d[0]);
  vst1q_s32(d + 4 , v_d[1]);
  vst1q_s32(d + 8 , v_d[2]);
  vst1q_s32(d + 12, v_d[3]);
  
  /* ... */
\end{lstlisting}

Oltre alle precedenti \emph{intrinsic} vengono utilizzate le seguenti:

\begin{itemize}
  \item \verb|vsubl_s16(int16x4_t a, int16x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Sub}tract \textbf{L}ong})\\
      Calcola le differenze a 16-bit tra i vettori \verb|a| e \verb|b|, il 
      risultato è salvato in un vettore a 32-bit.
  \item \verb|vaddq_s32(int32x4_t a, int32x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Add}})\\
      Calcola la somma a 32-bit tra i vettori \verb|a| e \verb|b|.
  \item \verb|vaddq_s32(int32x4_t a, int32x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Sub}tract})\\
      Calcola la differenza a 32-bit tra i vettori \verb|a| e \verb|b|.
  \item \verb|vst1q_s32(int32_t * ptr, int32x4_t val)| (\emph{\textbf{V}ector 
    \textbf{St}ore})\\
      Salva il vettore \verb|val| nell'\emph{array} di destinazione \verb|ptr|.
\end{itemize}

%-----------------------------------
%       SUBSECTION 4
%-----------------------------------

\subsection{Switch}

%TODO rivedere questa frase
Tra le ottimizzazioni possibili è stato dedicato del tempo alla sostituzione 
degli \verb|if| a valori costanti con equivalenti \verb|switch|.
In questi casi, infatti, il compilatore genera una \emph{jump table} basandosi 
sui valori che può assumere la variabile utilizzata per lo \verb|switch|.\\

Avendo identificato tra le funzioni più onerose \verb|filter|, verranno ora 
citati due spezzoni di codice da essa:

%TODO aggiungere style
\begin{lstlisting}
  c[0] = coeff[0];
  c[1] = coeff[1];
  
  if (N >= 4)
  {
    c[2] = coeff[2];
    c[3] = coeff[3];
  }
  if (N >= 6)
  {
    c[4] = coeff[4];
    c[5] = coeff[5];
  }
  if (N == 8)
  {
    c[6] = coeff[6];
    c[7] = coeff[7];
  }
  
  /* ... */
  
  sum    = src[col + 0 * cStride] * c[0];
  sum   += src[col + 1 * cStride] * c[1];
  
  if (N >= 4)
  {
    sum += src[col + 2 * cStride] * c[2];
    sum += src[col + 3 * cStride] * c[3];
  }
  if (N >= 6)
  {
    sum += src[col + 4 * cStride] * c[4];
    sum += src[col + 5 * cStride] * c[5];
  }
  if (N == 8)
  {
    sum += src[col + 6 * cStride] * c[6];
    sum += src[col + 7 * cStride] * c[7];
  }
\end{lstlisting}

Analizzando il codice è stato appurato che la variabile \verb|N| può assumere 
valori tra $4$ ed $8$. E' possibile quindi sostituire i blocchi di \verb|if| 
con dei più efficienti \verb|switch|. 
%Avendo cura di porre il caso più ricorrente per primo (\verb|N = 8|), è 
%%%possibile rimpiazzare tutte le istruzioni condizionali con una somma ed un 
%%%%\emph{jump} relativo.

%TODO style
\begin{lstlisting}
switch (N)
{
  case 8:
    c[7] = coeff[7];
    c[6] = coeff[6];
  case 7:
  case 6:
    c[5] = coeff[5];
    c[4] = coeff[4];
  case 5:
  case 4:
    c[3] = coeff[3];
    c[2] = coeff[2];
  default:
    c[1] = coeff[1];
    c[0] = coeff[0];
    break;
}

/* ... */

switch (N)
{
  case 8:
    sum += src[col + 7 * cStride] * c[7];
    sum += src[col + 6 * cStride] * c[6];
  case 7:
  case 6:
    sum += src[col + 5 * cStride] * c[5];
    sum += src[col + 4 * cStride] * c[4];
  case 5:
  case 4:
    sum += src[col + 3 * cStride] * c[3];
    sum += src[col + 2 * cStride] * c[2];
  default:
    sum += src[col + 1 * cStride] * c[1];
    sum += src[col + 0 * cStride] * c[0];
    break;
}
\end{lstlisting}

Riorganizzando il codice come sopra è possibile incrementare le prestazioni: 
viene effettuato un solo \emph{jump} all'istruzione corretta. Le seguenti sono 
già riordinate in modo tale da velocizzare il più possibile l'esecuzione del 
codice.\\

Questa modifica ha, ovviamente, un bassissimo impatto sulle prestazioni 
complessive del codice. E' stata implementata esclusivamente a scopo didattico.

%-----------------------------------
%       SUBSECTION 5
%-----------------------------------

\subsection{Attributi}
Oltre alle opzioni di compilazione, GCC mette a disposizione un insieme di   
attributi per descrivere esplicitamente il comportamento di funzioni (ma anche 
variabili e tipi), spesso con il fine di migliorare la qualità 
dell'ottimizzazione.\\
Gli attributi possono essere aggiunti con la keyword 
\verb|__attribute__((a1,a2,...))| inserita nella dichiarazione di una funzione 
tra il tipo di ritorno ed il nome.\\
Segue una lista con gli attributi presi in considerazione 
per l'ottimizzazione, anche se in seguito non sono stati sfruttati tutti.
 
\begin{itemize}
	\item\verb|hot|\\
	L'attributo \verb|hot| serve per comunicare che la funzione è un ``punto 
	caldo'', ovvero una funzione che si assume impegnare una 
	porzione considerevole del tempo di esecuzione del programma.
	Queste funzioni vengono ottimizzate più ``aggressivamente'', tipicamente a 
	spese della memoria, e vengono collocate insieme in una sezione speciale 
	per soddisfare maggiormente il principio della località, utile a diminuire 
	i \emph{cache miss}.\\
	\verb|hot| è stato applicato a \verb|filter|, alle funzioni 
	\verb|xCalcHADs| e \verb|xGetSAD|.
	
	\item\verb|always_inline|\\
	Ci sono casi in cui l'estensione \verb|__inline| viene ignorata dal 
	compilatore. Alcuni esempi sono la compilazione senza ottimizzazioni, le 
	funzioni che superano una certa soglia massima di lunghezza, misurata come 
	numero di istruzioni, oppure le funzioni la cui percentuale di espansione 
	causata da inline 
	$\nicefrac{\text{lunghezza}_\text{f}}{\text{lunghezza}_\text{i}}$ 
	 oltre una determinata soglia.
	Questo attributo permette di rendere inline una funzione ignorando tali 
	restrizioni. Nella pratica però è stato preferito \verb|__inline|, sia 
	perché come già detto le compilazioni vengono fatte in \verb|-Ofast|, sia 
	perché, durante le prove, \verb|always_inline| ha sempre generato errori di 
	compilazione. \verb|__inline| è stato applicato a \verb|filterCopy|, 
	\verb|filter|, a 
	tutte le \verb|xCalcHADs| e le \verb|xGetSAD|.

	\item\verb|pure|\\
	L'attributo \verb|pure| comunica al compilatore che la funzione non produce 
	effetti se non sul valore restituito, e che vengono considerati solo gli 
	argomenti passati alla funzione e le variabili globali. Queste funzioni 
	subiscono ottimizzazioni come la Common Subexpression Elimination (CSE) e 
	di loop. Queste ottimizzazioni si basano sul fatto 
	che, essendo \verb|pure|, la funzione non ha effetti collaterali sul 
	programma e 
	può quindi essere richiamata meno volte di quanto accade esplicitamente nel 
	codice, o, addiriturra, in posizioni diverse, a patto di non modificare i 
	parametri in ingresso. \verb|pure| è stato applicato a tutte le 
	funzioni \verb|xCalcHADs|
	
	\item\verb|const|\\
	L'attributo \verb|const| è simile a \verb|pure| ma più restrittivo, visto 
	che descrive una funzione che non accede nemmeno a variabili globali.
	Dato che una funzione \verb|const| può avere effetto solo sul valore 
	restituito e può accedere solo ai suoi argomenti, generalmente non ha senso 
	che la funzione restituisca \verb|void| o che i parametri siano dei 
	puntatori, a meno che non ci si aspetti che vengano modificati. 
	\verb|const| è stato applicato alle funzioni \verb|xGetSAD|.
	
	\item\verb|cold|\\
	L'attributo \verb|cold| viene utilizzato per dichiarare che una funzione 
	non occupa parti temporalmente rilevanti nell'esecuzione complessiva del 
	programma. Per questo motivo, GCC può evitare le ottimizzazioni più dure 
	risparmiando risorse che possono essere utilizzate per altre funzioni. 
	Anche questo attributo non è stato utilizzato in quanto, nonostante tutte 
	le ottimizzazioni implementate, il software non raggiunge mai i $300$ B di 
	memoria occupata (neanche $\nicefrac{1}{3}$ di quella disponibile) 
	\\ //AGGIUNGI CONFRONTO DIMENSIONE ESEGUIBILE opt/non opt.
\end{itemize}

L'utilizzo degli attributi, però, non ha avuto alcun riscontro sulle 
performance, che in media sono rimaste invariate. \\
// MOSTRA ASM DEI CAMBIAMENTI \\
// FAI IPOTESI
%-----------------------------------
%       SUBSECTION 6
%-----------------------------------

\subsection{Multithread}
Nonostante l'evoluzione di software ed hardware sia ormai da anni concentrata 
sulla parallelizzazione, HM non è stato pensato né scritto per tale 
caratteristica. Ne segue che una delle ottimizzazioni più doverose è stata il 
multithreading.
\par Teoricamente, il limite massimo raggiungibile dallo \emph{speedup} $S$ 
servendosi 
di $N$ thread paralleli è proprio $N$, ottenuto secondo la legge di Amdahl
$$S = \frac{1}{(1-P)+\frac{P}{N}}$$
essendo $P$ la frazione di codice parallelizzabile, dove $1$ corrisponde al 
$100\%$. Ponendo infatti $P = 1$ si ricava $S = N$. Ovviamente uno speedup 
esattamente di $N$ non si può mai ottenere, sia perché risulta molto difficile 
rendere 
$P$ precisamente $1$, sia perché la legge non tiene conto dell'overhead di 
controllo associato alla gestione della sincronizzazione dei thread, che 
tipicamente passa anche per il sistema operativo, rallentando ulteriormente.
\par Le strategie di parallelizzazione sono molteplici. Nell'ambito di questo 
lavoro ne abbiamo considerate due relativamente complementari, che aprono
una buona prospettiva per la discussione dei fattori che normalmente 
caratterizzano il software parallelo. Le tecniche esaminate sono la Wavefront 
Parallel Processing (WPP) e la Sequence Subdivision (SS) /*assolutamente da 
cambiare, nome scherzoso di fantasia*/.

\paragraph*{WPP} Questa tecnica consiste nella parallelizzazione della 
predizione e 
dell'entropy coding a livello di CTU. Come è noto, però, i CTU non sono 
indipendenti tra loro, e dunque le operazioni che li riguardano non possono 
essere parallelizzate senza i controlli adeguati. In particolare, la predizione 
e l'entropy coding di un CTU necessita delle informazioni relative ai blocchi 
vicini a sinistra, alto-sinitra, alto, alto-destra /*spiega perché*/. Questo 
significa che i thread devono essere in grado di attendere finché le 
informazioni necessarie al loro lavoro non diventano disponibili. \\
Una possibile realizzazione di questa tecnica consiste nell'utilizzo di una 
tavola condivisa tra i thread, per esempio attraverso un riferimento globale, 
con le informazioni circa lo stato di completamento dei vari CTU. Il codice dei 
singo thread si occupa quindi di consultare la tabella per decidere se operare 
sui prossimi CTB oppure attendere /*meglio sleep o nop?*/.\\
Un'altra complicazione sta nella gestione dell'ordine di esecuzione dei blocchi 
per evitare che più thread lavorino sullo stesso CTU. La soluzione più semplice 
è assegnare ad ogni thread una riga diversa servendosi di \verb|threadid|, un 
parametro normalmente impostato durante la creazione di un thread che ne 
rappresenta un identificativo unico e incrementale. Un generico thread lavora 
sulla riga $\verb|threadid| + r \cdot N$, dove $r$, inizialmente a $0$, viene 
incrementato di $1$ ogni volta che si terminata una riga, e $N$ è il numero di 
thread in parallelo.  \\
La percentuale di codice parallelizzabile non è il $100\%$ dato che, nonostante 
la parte predittiva e l'entropy encoding rappresentino buona parte della 
codifica H265, non ne costituiscono comunque la totalità.

\paragraph*{SS} Questa tecnica di parallelizzazione consiste nella suddivisione 
della sequenza di partenza in più parti indipendenti, intendendo per 
``parti'' blocchi di frame contigui.\\
Se $N$ è il numero di core a disposizione, 
si vuole suddividere la sequenza in $N$ parti omogenee (grandi uguale). I frame 
chiave sono quelli predetti interamente intra, visto che rompono ogni 
legame di dipendenza con quelli precedenti, e possono servire da riferimento 
per la suddivisione.\\
Successivamente è possibile far partire $N$ thread di encoding 
indipendenti, ciascuno su una parte diversa della sequenza. In seguito, data la 
struttura 
pacchettizzata dell'output di HEVC, è possibile ricomporre l'intera 
sequenza semplicemente congiungendo nel corretto ordine le $N$ sequenze binarie 
prodotte. \\
Come evidente, questa tecnica annulla ogni tipo di \emph{overhead} di 
sincronizzazione e gestione dei thread e permette di coprire il $100\%$ del 
codice per la parallelizzazione. Il difetto in questo caso non sta nel codice 
ma nei dati, perché per raggiungere lo speedup massimale è necessario che i 
frame intra siano disposti secondo una certa logica. Tuttavia, per garantire 
dei bunoi livelli di parallelismo, è sufficiente che il valore di 
\verb|intraperiod| (numero di frame tra due intra) sia sufficientemente più 
basso del numero complessivo di frame della sequenza da codificare. \\
Naturalmente anche in condizioni perfette non si può raggiungere uno speedup di 
$N$ per via delle procedure di avvio dei thread e di
unione delle sequenze binarie, che penalizzano la codifica 
rispetto alla versione \emph{singlethread}. La buona 
notizia è che tali operazioni sono trascurabili già con sequenze corte, e lo 
sono sempre più, in proporzione, con l'aumentare del numero di frame.\\
Infine è bene osservare che questa tecnica non può essere applicata 
nei casi di encoding in tempo reale, anche se ciò diventa secondario se si nota 
che HM di per sé non ammette tale opzione.
\par Segue uno schema che riassume le due tecniche.
\\ // DIMINUISCI LA LUNGHEZZA DELLA PRIMA COLONNA
\begin{center}
	\begin{tabularx}{\textwidth}{>{}X|>{}X|>{}X}
		
		    & Pros & Cons \\ \hline
		WPP & 
		    \begin{itemize}
		    	\item Più adatto ai casi reali
			\end{itemize}
			&
			\begin{itemize}
				\item Alto \emph{overhead}
				\item Difficoltà implementativa
				\item $P < 1$
			\end{itemize} \\ \hline
		SS &
		   \begin{itemize}
			   	\item Nessun \emph{overhead}
			   	\item Semplicità implementativa
			   	\item $P = 1$
		   \end{itemize}
		   &
		   \begin{itemize}
		   	    \item Preferibile \verb|intraperiod| basso
		   \end{itemize}
	\end{tabularx}
\end{center}
\paragraph*{} Come prima cosa abbiamo implementato la seconda tecnica, quella 
più 
semplice e verosimilmente la più efficiente, data la struttura fissata del GOP, 
riuscendo ad ottenere un quasi ideale fattore di speedup $S \approx 2$. In 
seguito abbiamo provato anche la prima, purtroppo senza successo dato l'elevato 
numero di modifiche, anche strutturali, che presentava un codice non 
predisposto all'esecuzione parallela.
\\Per programmare in \emph{multithreading} in C abbiamo utilizzato la libreria 
\verb|pthread| includendo \verb|pthread.h| e aggiungendo l'opzione di 
compilazione \verb|-pthread|.\\
Per avviare un thread è necessario costruirne la funzione principale seguendo 
il prototipo \verb|void *(*start_routine)(void*)|. Il parametro di ingresso di 
tipo \verb|void*| può essere utilizzato per fornire al thread dei dati 
preliminari, come \verb|threadid|, ma anche degli indirizzi di 
memoria dove il thread può registrare eventuali risultati o comunicazioni verso 
il resto del programma, oppure leggere eventuali comandi o dati dinamici 
provenienti da altri thread. \\
Scritta la routine, è possibile richiamare \verb|pthread_create| per creare e 
far partire il thread. \verb|pthread_join| può essere utilizzata per bloccare 
l'esecuzione del thread chiamante finché non è terminata quella di un altro 
thread specificato, utile per la sincronizzazione. Per terminare l'esecuzione 
di un thread, si può richiamare \verb|pthread_exit|, che ha lo stesso effetto 
di un semplice \verb|return(ptr)|.\\
Segue il codice scritto per l'implementazione.\\[8pt]
\begin{center}
\lstinputlisting[language=C,caption=]{Codes/multithreading.c}
\end{center}
La parte di main rimossa per brevità è poco interessante e consiste nella 
lettura dei parametri dai file di configurazione per la costruzione dei valori 
di input per il secondo thread, \verb|argc| e \verb|argv|.
