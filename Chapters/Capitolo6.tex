% Chapter 

\chapter{Il progetto} % Main chapter title

\label{Chapter6} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Capitolo 6. \emph{Il progetto}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%-------------------------------------------------------------------------------
%	SECTION 1
%-------------------------------------------------------------------------------

\section{Il setup della piattaforma}
La prima decisione che ha riguardato la piattaforma è stato il sistema 
operativo da installare. Vi sono a disposizione diversi sistemi 
Unix-like\footnote{http://www.lemaker.org/portal.php?mod=list\&catid=4}, 
dai più personalizzabili (come Gentoo o Arch Linux) a quelli più
 \emph{user-friendly} (come Lubuntu); la nostra scelta è ricaduta su Bananian, 
una distribuzione che deriva da Debian 7, appositamente ottimizzata per il 
Banana Pi, che abbiamo ritenuto essere il giusto compromesso tra usabilità
e assenza di software preinstallato a noi non necessario. \\
Nonostante la possibilità di lavorare senza ambiente grafico, da terminale, 
risparmiando qualche decina di \emph{megabyte} di RAM, inizialmente abbiamo 
deciso di avvalerci di LXDE, un ambiente desktop estremamente leggero, in modo da 
velocizzare la maggior parte delle nostre interazioni con il sistema. \\
\\ \\
Essendo tre persone a lavorare su una sola piattaforma, abbiamo optato 
per collocare la \emph{board} in un laboratorio dell'università, dotandola
di un sistema di controllo remoto basato su \emph{virtual network computing} 
(VNC), un sistema che utilizza un protocollo \emph{remote framebuffer} (RBF) 
per l'accesso remoto alle interfacce grafiche utente (meglio conosciute come 
\textbf{GUI}s, \textbf{G}raphical \textbf{U}ser \textbf{I}nterfaces). Inoltre, 
per facilitare l'accesso ai dati presenti sulle periferiche di memorizzazione, 
abbiamo dotato il Banana Pi di un server \emph{file transfer protocol} (FTP).
\\ \\ 
Tuttavia, nella fase finale del progetto, l'intefaccia grafica è stata 
abbandonata in modo da permettere una risposta del sistema più immediata e una 
minore allocazione di risorse; è stato dunque possibile disattivare 
l'accelerazione hardware, necessaria in un ambiente grafico, permettendo il 
risparmio di circa 30MB di RAM. Insieme alla GUI è stata accantonato il 
controllo remoto tramite VNC (fortemente dispendioso a causa del suo approccio 
\emph{pixel-based}) a favore di un accesso tramite SSH (\emph{secure shell}), 
più essenziale e meno dispersivo.

%-------------------------------------------------------------------------------
%	SECTION 2
%-------------------------------------------------------------------------------

\section{I tool per la compilazione}

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Il compilatore GCC}

%-----------------------------------
%       SUBSECTION 2
%-----------------------------------

\subsection{Il tool make}

%-------------------------------------------------------------------------------
%	SECTION 3
%-------------------------------------------------------------------------------

\section{I tool per valutare le prestazioni}
Per la valutazione delle prestazioni degli encoder da ottimizzare, è stato 
fatto uso di due strumenti software:
\begin{itemize}
\item Valgrind
\item gperftools
\end{itemize}
Entrambi \emph{opensource}, offrono diversi strumenti per l'analisi dinamica 
di un software; quelli utilizzati in questo progetto sono stati
\emph{Cachegrind} e \emph{Callgrind} per quanto riguarda il primo e il 
\emph{CPU profiler} del secondo.
%-------------------------------------------------------------------------------
%	SECTION 3
%-------------------------------------------------------------------------------

\section{I software di encoding presi in considerazione}
Inizialmente, tre software di encoding sono stati individuati come possibili
candidati per il progetto:
\begin{itemize}
\item f265
\item HM (\textbf{H}EVC Test \textbf{M}odel)
\item x265
\end{itemize}
Il primo è stato subito scartato non appena è stato chiaro che il sorgente non 
è compatibile con la piattaforma in nostro possesso (il codice è stato scritto 
unicamente per architettura x86).
I rimanenti due sono stati oggetto di 
%-------------------------------------------------------------------------------
%	SECTION 4
%-------------------------------------------------------------------------------

\section{Test preliminari}

%-------------------------------------------------------------------------------
%	SECTION 5
%-------------------------------------------------------------------------------

\section{Individuazione dei moduli H.265}

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Il tool KCacheGrind / QCacheGrind}

%-------------------------------------------------------------------------------
%	SECTION 6
%-------------------------------------------------------------------------------

\section{Strategie di ottimizzazione}

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Compilation flags}
Per prima cosa abbiamo dedicato del tempo allo studio delle opzioni di 
compilazione fornite da GCC (\emph{GNU Compiler Collection}) al fine di partire 
da una ``base stabile" da ottimizzare.\\
Particolare attenzione è stata dedicata ai \emph{flag} dedicati al 
miglioramento delle performance ed a quelli specifici per ARM.\\
\\
Senza alcuna opzione di compilazione espressa l'obiettivo del compilatore è 
quello di ridurre il più possibile il costo della compilazione e di rendere al 
contempo praticabile il \emph{debug} del programma. Per rendere possibile il 
//debug ciò è necessario in primo luogo che ogni \emph{statement} sia 
indipendente: è possibile fermare l'esecuzione in qualsiasi punto utilizzando 
un \emph{breakpoint} al fine di assegnare a piacere valori alle variabili e/o 
di modificare il \emph{program counter}, ottenendo i risultati attesi dal 
codice.\\
\\
Il compilatore ottimizza il codice basandosi sulla conoscenza che ha del 
programma. Non tutte le ottimizzazioni sono controllabili direttamente via 
\emph{flag}.\\
\\
Passiamo ora ad una breve descrizione delle opzioni utilizzate e dei loro 
effetti sull'eseguibile generato.

Famiglia `-O': opzioni dedicate all'ottimizzazione delle performance e/o della 
dimensione del compilato. La `O' è un diminutivo di ``Optimize".\\
Si distinguono vari livelli di ottimizzazione messi a disposizione dal 
compilatore GCC:
\begin{itemize}
\item \verb|-O0|\\
Opzione predefinita: riduce il tempo di compilazione cercando di dare la 
migliore esperienza di \emph{debug} possibile.
\item \verb|-O / -O1|\\
Abilita tutte le opzioni specificate da \verb|-O0|.\\
Il compilatore cerca di ridurre la dimensione del compilato ed il tempo di 
esecuzione utilizzando \emph{flag} che non peggiorano drasticamente il tempo 
di compilazione.
\item \verb|-O2|\\
Abilita tutte le opzioni specificate da \verb|-O / -O1|.\\
Vengono eseguite tutte le ottimizzazioni che non coinvolgono un 
\emph{trade-off} spazio-velocità. Rispetto al precedente migliora le 
prestazioni allungando il tempo di compilazione.
\item \verb|-Os|\\
Abilita tutte le opzioni specificate da \verb|-O2| che tipicamente non 
aumentano la dimensione dell'eseguibile. Vengono eseguite tutte le 
ottimizzazioni a favore dello spazio occupato dal compilato. La `s' è un 
diminutivo di ``size".
\item \verb|-O3|\\
Abilita tutte le opzioni specificate da \verb|-O2|.\\
Vengono eseguite tutte le ottimizzazioni a favore della velocità di esecuzione. 
Il tempo di compilazione aumenta così come lo spazio occupato dall'eseguibile 
generato. E' il massimo livello di ottimizzazione possibile insieme ad 
\verb|-Ofast|.
\item \verb|-Ofast|\\
Abilita tutte le opzioni specificate da \verb|-O3|.\\
Ignora l'adesione rigorosa allo standard abilitando \verb|-ffast-math|.
\item \verb|-Og|\\
Ottimizza l'esperienza di \emph{debug} abilitando tutte le opzioni che non 
interferiscono con quest'ultimo.
\end{itemize}

Opzioni di ottimizzazione indipendenti dall'hardware:

\begin{itemize}
\item \verb|-ftree-vectorize|\\
Abilita la vettorizzazione dei \emph{tree}.
// Che cos'è un tree?\\
Il compilatore cerca di riorganizzare dati in vettori permettendo così 
l'utilizzo di istruzioni SIMD (\emph{Single Instruction Multiple Data}) al fine 
di migliorare il tempo di esecuzione del codice.\\
Essa abilita inoltre \verb|-ftree-loop-vectorize| e 
\verb|-ftree-slp-vectorize|, che abilitano rispettivamente la vettorizzazione 
dei \emph{loop} e dei \emph{basic block}.
\item \verb|-finline-functions|\\
Considera tutte le funzioni come candidate per un possibile \emph{inlining}, 
anche quelle che non sono dichiarate esplicitamente come \verb|inline|.\\
Il compilatore decide attraverso un calcolo euristico di effettuare o no 
l'\emph{inlining} della funzione. 
\item \verb|-funswitch-loops|\\
Abilitata automaticamente con l'opzione \verb|-O3|.\\
Sposta i \emph{branch} con condizioni che non dipendono dal \emph{loop} al di 
fuori di quest'ultimo, duplicandolo su entrambi i \emph{branch} e modificandolo 
tenendo conto del risultato della condizione.
\item \verb|-funroll-loops|\\
Abilita l'\emph{unrolling} dei \emph{loop} per i quali è possibile determinare 
il numero di iterazioni a \emph{compile time}.
// Aggiungere -fwhole-program?
\end{itemize}

Opzioni di ottimizzazione specifiche per l'hardware ARM:

\begin{itemize}
\item \verb|-march=|\emph{name}\\
Specifica il nome dell'architettura ARM di destinazione.\\
Questo parametro viene utilizzato da GCC per determinare che tipo di istruzioni 
possono essere emesse quando viene generato il codice assembly relativo al 
programma.
\item \verb|-mtune=|\emph{name}\\
Specifica il nome del processore ARM per il quale GCC deve ottimizzare il 
codice. Su alcune implementazioni possono essere ricavate prestazioni migliori 
specificando questa opzione.
\item \verb|-mfpu=|\emph{name}\\
Specifica quale hardware (o emulazione hardware) \emph{floating-point} è 
disponibile sul dispositivo.\\
Quest'opzione è \underline{necessaria} per poter utilizzare le varie SIMD (in 
questo caso NEON) messe a disposizione dall'architettura ARM.
\item \verb|-mfloat-abi=|\emph{name}\\
Specifica quale ABI (o \emph{Application Binary Interface}) utilizzare per le 
operazioni \emph{floating-point}. // Che cos'è un ABI? \\
Quest'opzione è \underline{necessaria} per poter utilizzare le varie SIMD (in 
questo caso NEON) messe a disposizione dall'architettura ARM.
\end{itemize}

Opzioni del linguaggio e del \emph{debug}.

\begin{itemize}
\item \verb|-fopt-info-|\emph{options}\\
Mostra un \emph{log} contenente informazioni su ciò che è o non è stato 
ottimizzato.
\item \verb|-std=|\emph{name}\\
Determina quale standard utilizzare per il linguaggio C da compilare.
\item \verb|-pthread|\\
Abilita il supporto al \emph{multithreading} con la libreria \emph{phtreads}.
\end{itemize}

Queste opzioni sono state testate modificando il file \verb|makefile.base|, 
contenuto nella cartella \verb|/build/linux/common/|. Di seguito le linee 
dall'originale:\\

\begin{lstlisting}[language=make]
# default cpp flags for all configurations
CPPFLAGS          = -fPIC $(DEFS) -I$(CURDIR)/$(INC_DIR) $(USER_INC_DIRS) -Wall
                    -Wshadow -Wno-sign-compare -Werror
# debug cpp flags
DEBUG_CPPFLAGS    = -g -D_DEBUG
# release cpp
RELEASE_CPPFLAGS  = -O3 -Wuninitialized
\end{lstlisting}

Per prima cosa è stato cambiato il livello di ottimizzazione da \verb|-O3| a 
\verb|-Ofast| per quanto riguarda i \verb|RELEASE_CPPFLAGS|.\\
Questa modifica è stata effettuata al fine di migliorare le \emph{performance} 
sulle operazioni matematiche, è stato inoltre verificato che il comportamento 
del programma non fosse cambiato (\verb|-ffast-math| può portare a risultati 
sbagliati in certe configurazioni).\\
Assieme a suddetta modifica è stato cambiato il \emph{flag} \verb|-g| in 
\verb|-Og| per quanto riguarda i \verb|DEBUG_CPPFLAGS|.\\
Questo al fine di velocizzare il più possibile il \emph{debug} 
dell'applicazione, particolarmente lento utilizzando \verb|-g|.\\
Sono state poi inserite tutte le opzioni relative all'hardware ARM in 
\verb|CPPFLAGS|, i \emph{flag} condivisi da tutte le configurazioni.\\
Nello specifico sono state inserite le seguenti voci: \verb|-march=armv7-a|, 
\verb|-mtune=cortex-a7|, \verb|-mfpu=neon|, \verb|-mfloat-abi=softfp|.\\
Subito dopo questa modifica è stato ancora aggiunta ai \verb|RELEASE_CPPFLAGS| 
l'opzione \verb|-ftree-vectorize|.\\
\\
Prima di iniziare la modifica vera e propria del codice è stata effettuata 
un'analisi mediante l'utilizzo di \verb|-fopt-info-vec-optimized| al fine di 
sapere cosa fosse stato già vettorizzato automaticamente da GCC. Questo ci ha 
permesso di focalizzarci maggiormente sulle funzioni onerose non modificate.\\
\\
E' stato inoltre deciso di rendere \emph{multithread} il programma.\\
E' stato in primo luogo provato il \emph{multithreading} offerto dallo standard 
C++11, aggiungendo quindi \verb|-std=c++11| alle opzioni esistenti.\\
Avendo però notato un degrado delle performance generali in \emph{single 
thread}, sì è deciso di utilizzare la libreria \emph{pthreads} e quindi di 
sostituire il \emph{flag} \verb|-std=c++11| con \verb|-pthread|.

Il file \verb|makefile.base| finale è quindi il seguente:\\

\begin{lstlisting}[language=make]
# default cpp flags for all configurations
CPPFLAGS          = -fPIC $(DEFS) -I$(CURDIR)/$(INC_DIR) $(USER_INC_DIRS) -Wall 
                    -Wshadow -Wno-sign-compare -Werror -march=armv7-a 
                    -mtune=cortex-a7 -mfpu=neon -mfloat-abi=softfp -pthread
# debug cpp flags
DEBUG_CPPFLAGS    = -Og -D_DEBUG
# release cpp
RELEASE_CPPFLAGS  = -Ofast -Wuninitialized -ftree-vectorize
\end{lstlisting}


// Tentativi con -fwhole-program.\\
// gcc-4.7 non vettorizzava ARM, gcc-4.9 sì.\\
// Risultati\\
%-----------------------------------
%       SUBSECTION 2
%-----------------------------------

\subsection{Assembly}
// IMPOSTA FONT CONSOLAS PER I LISTATI \newline
// INGRANDISCI IL FONT DI TESTO E LISTATI \newline
Un'altra ottimizzazione sperimentata inizialmente è stata
 la stesura di funzioni in Assembly nel tentativo di ottimizzare alcune parti 
 di codice delle funzioni più onerose di HM.
Le principali caratteristiche del linguaggio Assembly ARM che velocizzano un 
programma sono le istruzioni condizionali e il \emph{barrel
 	 shifter}. \newline
Le istruzioni condizionali sono normali istruzioni la cui esecuzione dipende
dal valore di determinati \emph{flag}. In questo modo è possibile evitare
parecchi branch condizionali che rallentano il codice perché rompono la
\emph{pipeline}.\newline
Il \emph{barrel shifter} è un'unità che compie una pre-elaborazione di uno dei 
due operandi di un'istruzione attraverso una normale operazione di shift dei 
bit. \newline
//SPIGA PERCHE IL BARREL SHIFTER VELOCIZZA (NON AGGIUNGE TEMPO ESECUZIONE)
//AGGIUNGI IMMAGINE BARREL SHIFTER \newline

\par Per esempio, la funzione matematica $\text{clamp}(x) = 
\max(a,\min(x,b))$, assente dalla libreria standard, viene implementata da 
\verb+filter+ in questo modo:
\lstinputlisting[language=C,caption=]{Codes/cclamp.c}
Questo codice viene tradotto in \verb|-Ofast| in una dozzina di istruzioni con 
due \emph{compare}. Notando che nel codice di HM \verb|minVal| vale sempre 0, è 
possibile introdurre un'ottimizzazione che sfrutta il barrel shifter. \newline
Segue il confronto tra l'estratto del codice Assembly generato da GCC (a 
sinistra) e quello da noi scritto per eseguire clamp.
// ALLINEA VERTICALMENTE I DUE LISTATI

\lstset{style=cstyle}
\begin{center}
  \begin{tabularx}{\textwidth}{ X | c }
  	\hline
    \lstinputlisting[caption=]{Codes/armgccclamp.s}
    \xdef\tempwidth{\thelstlisting\linewidth} &
    \lstinputlisting[stepnumber=0,caption=]{Codes/armclamp.s} \\
    \hline
  \end{tabularx}
\end{center}
Per maggiore chiarezza il codice generato da GCC è stato commentato riga per 
riga e viene discusso a seguire. \newline
Le prime due linee caricano 0 e \verb|val|, che inizia a partire da 4 byte dalla
 posizione puntata da \verb|SP| (Stack Pointer), rispettivamente nei registri
  \verb|r2| e \verb|r3|.\newline La terza linea esegue l'operazione
   \verb|r3 - r2| aggiornando i flag contenuti in \verb|CPSR| (Current Program 
Status Register).\newline L'istruzione \verb|itt lt| abilita la condizione 
\verb|lt| (lower than) per le successive due istruzioni, che verranno quindi 
eseguite solo se \verb|r3| $<$ \verb|r2|. Ciò si riflette sull'\emph{opcode}
delle due istruzioni successive, che eredita il suffisso \verb|lt|. Queste
istruzioni mettono 0 in \verb|r3| e lo salvano in \verb|val|. \newline
Le restanti istruzioni eseguono il secondo \verb|if| in maniera analoga.\newline
Nel nostro codice la terza linea compendia quello che in C sarebbe 
\verb|if(r3 < 0) r3 = 0|. Il suffisso \verb|s| specifica che l'istruzione 
aggiorna anche il 
registro \verb|CPSR|, così, se il risultato è positivo (i.e. \verb|r3| $>$ 0), 
si procede con le istruzioni 5 e 6 che sostituiscono \verb|maxVal| a \verb|r3| 
nel caso in cui \verb|r3| $>$ \verb|maxVal|.
\par Nonostante gli esiti positivi dell'ottimizzazione in fase di
testing, dopo l'implementazione effettiva all'interno di HM la performance 
dell'encoder è calata, come mostra la tabella.
\begin{center}
  \begin{tabular}{l | l | l}
    & ASM & C \\ \hline
    $8\cdot10^9$ clamp & $7065.6$ (ms) & $8072.7$ (ms) \\
    $50$ frame \verb|highway_cif.yuv| & $1493.6142$ (s) &  $1408.4262$ (s) \\
  \end{tabular}
\end{center}
Le righe della tabella mostrano rispettivamente una media delle prove
fatte con un 
codice di test 
compilato in \verb|-Ofast| /*INSERISCI IL CODICE IN APPENDICE*/ e implementando
l'ottimizzazione nel software.\newline
Il motivo di tale discrepanza può essere visto 
nel fatto che, vicino alla funzione Assembly inline, GCC è costretto ad 
inserire un prologo ed un epilogo in cui salva e carica lo stato del programma, 
mentre in una serie di test ciò non è necessario.\newline
Una possibile soluzione consiste nel riscrivere l'intera funzione \verb|filter| 
in Assembly in maniera da predisporre correttamente i dati, eventualmente
ottimizzando anche altre parti del codice, ma è un'operazione che al momento 
esula dalle nostre competenze. // PROVA A FARLO

%-----------------------------------
%       SUBSECTION 3
%-----------------------------------

\subsection{NEON intrinsics}

Tra le varie ottimizzazioni che implicavano la modifica del codice, è stato 
dato largo spazio alle SIMD di ARM: le cosiddette NEON.\\
La tecnologia NEON permette di accelerare le operazioni matematiche più usate 
permettendo di effettuare più calcoli in parallelo.\\
Architettura introdotta con ARMv7, utilizza 32 registri a 64-bit interpretati 
come ``vettori di elementi''. I registri possono essere accoppiati in modo da 
lavorare con vettori a 128 bit, ognuno di essi può essere utilizzato come:

\begin{itemize}
  \item Un vettore con 2 elementi da 64 bit ciascuno.
  \item Un vettore con 4 elementi da 32 bit ciascuno.
  \item Un vettore con 8 elementi da 16 bit ciascuno.
  \item Un vettore con 16 elementi da 8 bit ciascuno.
\end{itemize}

Tutti gli elementi (\emph{lanes}) di un vettore devono essere dello stesso 
tipo, nello specifico possono essere:

\begin{itemize}
  \item Un intero \emph{signed} oppure \emph{unsigned}.
  \item Un \emph{floating-point} a singola precisione: \verb|float|.
\end{itemize}

Ogni istruzione NEON effettua la \textbf{stessa} operazione su tutti i 
\emph{lane}.\\

Per poter utilizzare le \emph{intrinsic} NEON in un contesto C (ma anche C++) è 
necessario includere la libreria \verb|arm_neon.h| ed aggiungere le opzioni di 
compilazione relative all'hardware \emph{floating-point}: \verb|-mfpu=neon| e 
\verb|-mfloat-abi=softfp|. Una spiegazione più approfondita dei sopracitati 
\emph{flag} è stata data nella sezione dedicata alle opzioni di compilazione.\\

Avendo alla mano i dati sulle funzioni più onerose in termini di istruzioni, 
facendo un controllo incrociato con \emph{log} generato dall'opzione 
\verb|-fopt-info-vec-optimized|, si è osservato che tutte le la quasi totalità 
di quelle dedicate alla SAD (\emph{Sum of Absolute Differences}) era stata 
automaticamente vettorizzata.\\

Il lavoro con le \emph{intrinsic} è iniziato da lì. Verranno spiegati i 
passaggi a partire dal codice originale di \verb|xGetSAD8|, il procedimento è 
stato riprodotto in modo analogo per tutte le altre funzioni.\\

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  Distortion uiSum = 0;
  
  for ( ; iRows != 0; iRows -= iSubStep)
  {
    uiSum += abs(piOrg[0] - piCur[0]);
    uiSum += abs(piOrg[1] - piCur[1]);
    uiSum += abs(piOrg[2] - piCur[2]);
    uiSum += abs(piOrg[3] - piCur[3]);
    uiSum += abs(piOrg[4] - piCur[4]);
    uiSum += abs(piOrg[5] - piCur[5]);
    uiSum += abs(piOrg[6] - piCur[6]);
    uiSum += abs(piOrg[7] - piCur[7]);
    
    piOrg += iStrideOrg;
    piCur += iStrideCur;
  }
\end{lstlisting}

Dove \verb|Distortion| è del tipo \verb|uint32_t| (rappresentante un intero 
\emph{unsigned} a 32-bit), mentre \verb|piOrg| e \verb|piCur| sono del tipo 
\verb|int16_t *| (rappresentanti un \emph{array} di interi \emph{signed} a 
16-bit).\\

Il codice si presta molto bene ad essere vettorizzato utilizzando le SIMD NEON:

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  // Set all v_iSum lanes to 0
  int16x8_t v_iSum = vdupq_n_s16(0);
  
  for ( ; iRows != 0; iRows -= iSubStep)
  {
    // Load 8 elements into vector
    int16x8_t v_piOrg = vld1q_s16(piOrg);
    int16x8_t v_piCur = vld1q_s16(piCur);
    
    // v_iSum += |v_piOrg - v_piCur|
    v_iSum = vabaq_s16(v_iSum0, v_piOrg, v_piCur);
  
    piOrg += iStrideOrg;
    piCur += iStrideCur;
  }
  
  // Sum all lanes in v_iSum
  Distortion uiSum = (Distortion)(
      vgetq_lane_s16(v_iSum, 0) + vgetq_lane_s16(v_iSum, 1) +
      vgetq_lane_s16(v_iSum, 2) + vgetq_lane_s16(v_iSum, 3) +
      vgetq_lane_s16(v_iSum, 4) + vgetq_lane_s16(v_iSum, 5) +
      vgetq_lane_s16(v_iSum, 6) + vgetq_lane_s16(v_iSum, 7)
    );
\end{lstlisting}

Le \emph{intrinsic} utilizzate sono le seguenti:

\begin{itemize}
  \item \verb|vdupq_n_s16(int16_t value)| (\emph{\textbf{V}ector 
    \textbf{Dup}licate})\\
      Carica in tutti gli elementi del vettore il valore espresso da 
      \verb|value|.\\
      La \verb|q| indica che l'operazione viene effettuata a 128 bit invece dei 
      canonici 64, mentre \verb|s16| (\emph{\textbf{S}igned \textbf{16}}) 
      indica il tipo dato di ogni elemento.
  \item \verb|vld1q_s16(int16_t const * ptr)| (\emph{\textbf{V}ector 
    \textbf{L}oa\textbf{d}})\\
      Carica tutti gli elementi del vettore a partire da un \emph{array} dello 
      stesso tipo presente in memoria.
  \item \verb|vabaq_s16(int16x8_t a, int16x8_t b, int16x8_t c)| 
    (\emph{\textbf{V}ector \textbf{Ab}solute Difference and 
    \textbf{A}ccumulate})\\
      Ritorna il valore assoluto della differenza tra \verb|b| e \verb|c| 
      aggiungendoci il valore di \verb|a|.
  \item \verb| vgetq_lane_s16(int16x8_t vec, int lane)| (\emph{\textbf{V}ector 
    \textbf{Get} \textbf{Lane}})\\
      Ritorna il valore dell'elemento \verb|lane|-\emph{esimo} del vettore 
      \verb|vec|.      
\end{itemize}

E' stato osservato come sia più veloce l'utilizzo di \verb|vgetq_lane_s16| su 
ogni componente di \verb|v_iSum| al fine di ricavare la somma di tutte le 
componenti del vettore. Degno di nota il fatto che a partire da ARMv8 sia stata 
inserita un'\emph{intrinsic} dedicata a questa operazione.\\

Più spinosa è stata la vettorizzazione delle funzioni dedicate al calcolo della 
trasformata Walsh–Hadamard su blocchi di immagine, già implementata nella sua 
versione \emph{fast}. Questa categoria di funzioni è stata vettorizzata solo 
parzialmente ma, essendo le più onerose, il miglioramento prestazionale è stato 
significativo.\\

Di seguito un estratto della versione originale di \verb|xCalcHADs4x4|, presa 
come esempio:

%TODO sostituire [language=C] con lo stile personalizzato.
\begin{lstlisting}[language=C]
  Int k;
  Distortion satd = 0;
  
  TCoeff diff[16], m[16], d[16];
  
  for (k = 0; k < 16; k += 4)
  {
    diff[k+0] = piOrg[0] - piCur[0];
    diff[k+1] = piOrg[1] - piCur[1];
    diff[k+2] = piOrg[2] - piCur[2];
    diff[k+3] = piOrg[3] - piCur[3];
  
    piCur += iStrideCur;
    piOrg += iStrideOrg;
  }
  
  m[ 0] = diff[ 0] + diff[12];
  m[ 1] = diff[ 1] + diff[13];
  m[ 2] = diff[ 2] + diff[14];
  m[ 3] = diff[ 3] + diff[15];
  
  m[ 4] = diff[ 4] + diff[ 8];
  m[ 5] = diff[ 5] + diff[ 9];
  m[ 6] = diff[ 6] + diff[10];
  m[ 7] = diff[ 7] + diff[11];
  
  m[ 8] = diff[ 4] - diff[ 8];
  m[ 9] = diff[ 5] - diff[ 9];
  m[10] = diff[ 6] - diff[10];
  m[11] = diff[ 7] - diff[11];
  
  m[12] = diff[ 0] - diff[12];
  m[13] = diff[ 1] - diff[13];
  m[14] = diff[ 2] - diff[14];
  m[15] = diff[ 3] - diff[15];
  
  d[ 0] = m[ 0] + m[ 4];
  d[ 1] = m[ 1] + m[ 5];
  d[ 2] = m[ 2] + m[ 6];
  d[ 3] = m[ 3] + m[ 7];
  d[ 4] = m[ 8] + m[12];
  d[ 5] = m[ 9] + m[13];
  d[ 6] = m[10] + m[14];
  d[ 7] = m[11] + m[15];
  d[ 8] = m[ 0] - m[ 4];
  d[ 9] = m[ 1] - m[ 5];
  d[10] = m[ 2] - m[ 6];
  d[11] = m[ 3] - m[ 7];
  d[12] = m[12] - m[ 8];
  d[13] = m[13] - m[ 9];
  d[14] = m[14] - m[10];
  d[15] = m[15] - m[11];
  
  /* ... */
\end{lstlisting}

Dove \verb|Int| e \verb|TCoeff| sono entrambi del tipo \verb|int32_t| 
(rappresentanti un intero \emph{signed} a 32-bit).\\

In questo caso è stata mostrata solo la porzione di codice che ha subito 
modifiche per un migliore raffronto.\\

Viene ora presentata la versione vettorizzata.

%TODO usare style
\begin{lstlisting}[language=C]
  Int k;
  Distortion satd = 0;
  
  TCoeff m[16], d[16];
  int32x4_t v_diff[4], v_m[4], v_d[4];
  
  for (k = 0; k < 4; k++)
  {
    int16x4_t v_piOrg = vld1_s16(piOrg);
    int16x4_t v_piCur = vld1_s16(piCur);
    
    v_diff[k] = vsubl_s16(v_piOrg, v_piCur);
  
    piCur += iStrideCur;
    piOrg += iStrideOrg;
  }
  
  v_m[0] = vaddq_s32(v_diff[0], v_diff[3]);
  v_m[1] = vaddq_s32(v_diff[1], v_diff[2]);
  v_m[2] = vsubq_s32(v_diff[1], v_diff[2]);
  v_m[3] = vsubq_s32(v_diff[0], v_diff[3]);
  
  // Store 'v_m' in 'm'
  vst1q_s32(m     , v_m[0]);
  vst1q_s32(m + 4 , v_m[1]);
  vst1q_s32(m + 8 , v_m[2]);
  vst1q_s32(m + 12, v_m[3]);
  
  v_d[0] = vaddq_s32(v_m[0], v_m[1]);
  v_d[1] = vaddq_s32(v_m[2], v_m[3]);
  v_d[2] = vsubq_s32(v_m[0], v_m[1]);
  v_d[3] = vsubq_s32(v_m[3], v_m[2]);
  
  // Store 'v_d' in 'd'
  vst1q_s32(d     , v_d[0]);
  vst1q_s32(d + 4 , v_d[1]);
  vst1q_s32(d + 8 , v_d[2]);
  vst1q_s32(d + 12, v_d[3]);
  
  /* ... */
\end{lstlisting}

Oltre alle precedenti \emph{intrinsic} vengono utilizzate le seguenti:

\begin{itemize}
  \item \verb|vsubl_s16(int16x4_t a, int16x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Sub}tract \textbf{L}ong})\\
      Calcola le differenze a 16-bit tra i vettori \verb|a| e \verb|b|, il 
      risultato è salvato in un vettore a 32-bit.
  \item \verb|vaddq_s32(int32x4_t a, int32x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Add}})\\
      Calcola la somma a 32-bit tra i vettori \verb|a| e \verb|b|.
  \item \verb|vaddq_s32(int32x4_t a, int32x4_t b)| (\emph{\textbf{V}ector 
    \textbf{Sub}tract})\\
      Calcola la differenza a 32-bit tra i vettori \verb|a| e \verb|b|.
  \item \verb|vst1q_s32(int32_t * ptr, int32x4_t val)| (\emph{\textbf{V}ector 
    \textbf{St}ore})\\
      Salva il vettore \verb|val| nell'\emph{array} di destinazione \verb|ptr|.
\end{itemize}

%-----------------------------------
%       SUBSECTION 4
%-----------------------------------

\subsection{Switch}

%-----------------------------------
%       SUBSECTION 5
%-----------------------------------

\subsection{Attributes}

%-----------------------------------
%       SUBSECTION 6
%-----------------------------------

\subsection{Multithread}

