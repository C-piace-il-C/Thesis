% Chapter Template

\chapter{La necessità di comprimere i dati} % Main chapter title

\label{Chapter3}

\lhead{Capitolo 3. \emph{La necessità di comprimere i dati}}

%-------------------------------------------------------------------------------
%	SECTION 1
%-------------------------------------------------------------------------------

\section{Compressione dati}
La disponibilità di calcolatori sempre più potenti ad un costo sempre più
contenuto ha portato alla conseguente possibilità di effettuare elaborazioni
via via più complesse, incrementando di pari passo la mole di dati su cui
queste elaborazioni vengono svolte. \\
Per fare un esempio nel 1988 venne proposto, all'interno di H.261, lo standard
\emph{Common Intermediate Format} (CIF) per uniformare la risoluzione verticale
ed orizzontale delle sequenze video solitamente utilizzate nelle teleconferenze.
Lo standard prevede una risoluzione pari a $352{\times}288$ pixel ed un
\emph{frame rate} pari a 30000/1001 (circa 29.97) \emph{frame} al secondo;
prendendo in considerazione una codifica senza compressione in uno spazio
colore RGB con 8 bit per canale ed applicando la formula
\begin{align*}
  \frac{W \cdot H \cdot bit\_depth\cdot fps} 
  {8\cdot10^6} \ \nicefrac{\text{MB}}{\text{s}}
\end{align*}%Perché bit_depth/3? così si ottiene il peso per la trasmissione di 
%un solo canale..
%ragazzi.. W*H*bit_depth*fps è il numero di bit per un secondo di video.. 
%quindi per ottenere i megabyte dobbiamo dividere per 8*10^6
%e poi MB/s = ... ma è un'unità di misura, dai
dove $bit\_depth$ è il numero di bit per la codifica del colore, in questo caso 
24, e $fps$ è il numero di frame al secondo,
si ottiene che un secondo di sequenza video pesa circa 9 \emph{megabyte}. \\
Considerando la capacità tipica di un disco rigido dell'epoca (compresa
tra i 20 e i 60MB), la sua velocità di scrittura/lettura o la larghezza di 
banda necessaria a trasmettere una tale sequenza, risulta evidente come la 
compressione dei dati sia stata una grande necessità; se effettuiamo lo stesso 
calcolo utilizzando una risoluzione standard moderna (e.g., 
$1920{\times}1080$), 
otteniamo un peso di circa 187MB per ogni secondo contenuto nella sequenza 
video. \\
Sebbene a tutt'oggi le capacità di memorizzazione siano incrementate di fattori
che variano tra le $12\,500$ e le $200\,000$ volte\footnote{Sono state 
confrontate rispettivamente capacità di 500GB e 8TB con la capacità media di 
40MB dell'epoca.}, la velocità di trasmissione dei dati non è aumentata di pari 
passo, mentre è esploso il traffico di contenuti video online; la compressione 
dei dati rimane comunque anche un'ottima risorsa per
poter immagazzinare grandi quantità di dati preservandone la qualità originale, 
o almeno quella percepita.
%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Compressione \emph{lossless}}

Gli algoritmi di compressione senza perdita (\emph{lossless}) cercano 
solitamente di rimuovere le ridondanze dovute alle correlazioni naturalmente 
presenti nell'informazione di interesse, per rappresentare i
dati nel modo più sintetico possibile senza andare ad intaccare il messaggio
originale, ovvero senza causare alcuna perdita d'informazione.
\\ \\ %per uniformare il .tex
Il limite di questa classe di algoritmi è posto dal primo teorema di 
Shannon, che definisce il significato operativo di entropia e vincola la 
massima compressione ottenibile; normalmente è estremamente 
dispendioso in termini computazionali avvicinarsi all'esatto limite teorico 
della lunghezza di codifica. %se diciamo eccetto alcuni casi particolari poi 
%bisognerebbe saperne fare un esempio
%non sarebbe stato male enunciare il teorema e aggiungere bibliografia
\\ \\
Queste tecniche sono necessarie laddove non sia ammessa la corruzione del dato 
originale: compressione di documenti e programmi, ma anche di audio e video ad 
alta qualità per applicazioni professionali o scientifiche, come l'estrazione 
di informazione da parte di un calcolatore.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Compressione \emph{lossy}}

Se l'applicazione non richiede la ricostruzione esatta del messaggio originale 
è possibile utilizzare algoritmi di compressione più efficaci, %non efficienti
ammettendo una certa perdita di informazione (compressione \emph{lossy}).
Questa classe di algoritmi è pensata su misura d'uomo:
si sfrutta infatti la conoscenza sugli organi sensoriali umani al 
fine di rendere impercettibile la perdita d'informazione rimuovendo quel  
contenuto che non potrebbe comunque essere percepito, in
%stiamo parlando di compressione in generale, non solo audio video
aggiunta a tutte le tecniche di compressione \emph{lossless}.
La resa della compressione \emph{lossy} è molto superiore rispetto 
alla variante senza perdita: nel caso di audio ed immagini la dimensione del 
risultato rispetto all'originale passa in media dal $50\%$ della 
variante \emph{lossless} al $10\%$ se viene utilizzata una compressione 
\emph{lossy}.

%-------------------------------------------------------------------------------
%	SECTION 2
%-------------------------------------------------------------------------------

\section{Compressione di immagini}

% \subsection{Il sistema visivo umano}

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Utilizzo delle trasformate}

I metodi più diffusi per quanto riguarda la compressione di immagini prevedono 
l'utilizzo di trasformate con lo scopo di rendere l'immagine più adatta ad 
essere codificata: questa viene prima divisa in blocchi di dimensioni ridotte, 
$N\times N$, solitamente quadrate e non superiori a $64\times64$.\\

Su ogni blocco viene effettuata una trasformata, 
il cui obiettivo è quello di decorrelare il più possibile il segnale originale.
La bontà di una trasformata viene solitamente definita in base alle sue 
capacità di decorrelazione e implementazione veloce.\\

Tra le trasformate si ricordano:

\begin{itemize}
  
  \item \textbf{\emph{Discrete Fourier transform} (DFT)}\\
    Largamente utilizzata in analisi e filtraggio, ha la proprietà di avere un 
    nucleo separabile (rendendo possibile quindi il calcolo della trasformata 
    isolatamente su righe e colonne). Ha una sua implementazione veloce, 
    \emph{Fast Fourier Transform} (FFT), che ne rende l'utilizzo 
    particolarmente 
    desiderabile.
    
  \item \textbf{\emph{Karhunen–Loève transform} (KLT)}\\
    Fornisce la miglior compressione d'energia rispetto alle altre 
    trasformazioni possibili. Purtroppo la mancanza di un algoritmo veloce e la 
    necessità di uno studio della covarianza dell'immagine da comprimere per la 
    generazione delle funzioni base la rendono scarsamente utilizzata.
    
  \item \textbf{\emph{Discrete Cosine transform} (DCT)}\\
    Analoga alla DFT, da cui differisce per l'utilizzo di soli coseni come 
    funzioni base.
    Permette di ottenere una decorrelazione simile a quella ottenibile %daie 
    %con ste ripetizioni
    trasformando con la KLT. La presenza di un algoritmo veloce la rende 
    tutt'ora la trasformata più utilizzata per la compressione d'immagini.
   
  \item \textbf{\emph{Walsh-Hadamard transform} (WHT)}\\
    La peggiore in termini di compattamento d'energia, ha la proprietà di poter 
    essere eseguita con sole somme e sottrazioni ed ha una sua versione 
    \emph{fast}; il bassissimo costo computazionale l'ha resa largamente 
    utilizzata.
    
\end{itemize}

%-----------------------------------
%       SUBSECTION 2
%-----------------------------------

\subsection{Principali algoritmi}
  % per uniformare
  \textbf{Run-length encoding} \\
  La compressione RLE è una forma molto semplice di codifica d'immagine 
  \emph{lossless}: applicata solitamente a immagini in bianco e nero, sfrutta 
  il fatto che pixel bianchi e neri si presentano in sequenza. Invece di 
  trasmettere singolarmente i bit dell'immagine vengono trasmesse le lunghezze 
  (\emph{length}) dei tratti (\emph{run}) aventi lo stesso colore.
  \\ \\
  \textbf{Differential Pulse-Code Modulation lossless} \\
  La codifica DPCM sfrutta la correlazione tra i \emph{pixel} adiacenti di 
  un'immagine: si prova a predire il valore di un pixel a partire da quelli 
  vicini già conosciuti. Questo tipo di codifica permette di avvicinarsi molto 
  al limite massimo di compressione \emph{lossless}.\\
  Il principio di funzionamento è molto semplice: si genera l'immagine predetta 
  e se ne fa la differenza con l'originale, ricavando quindi la funzione 
  ``errore'', che verrà in seguito codificata. Il vantaggio rispetto alla 
  semplice codifica dei pixel risiede nel fatto che la suddetta funzione è molto
  meno autocorrelata rispetto all'originale.
  %l'originale è l'immagine, quindi l'immagine è correlata all'immagine.lul.
  \\ \\
  \textbf{Joint Photographic Experts Group} \\
  JPEG è un formato molto utilizzato per la compressione \emph{lossy} di 
  immagini digitali, in particolar modo per quelle fotografiche. La codifica 
  JPEG sfrutta alcune peculiarità del sistema visivo umano per poter comprimere 
  il più possibile un'immagine senza che il fruitore (l'uomo) possa accorgersi 
  della differenza rispetto all'orginale. Non esiste una sola versione 
  dell'algoritmo: JPEG/Exif è il più comune nelle immagini generate da 
  fotocamere digitali mentre JPEG/JFIF è utilizzato maggiormente per salvare e 
  trasmettere immagini su Internet, questo per citare solo le due versioni più 
  utilizzate. \\
  Tra le varie strategie sfruttate da JPEG per aumentare la compressione si 
  ricorda il \textit{chroma subsampling}, il sottocampionamento del piano 
  colore. L'occhio umano, infatti, percepisce meglio le variazioni di 
  \textit{luma} (luminosità) rispetto a quelle di \textit{chroma} (colore).
  %TODO spiegare che YCrCb è uno spazio colore completo, si può passare da RGB 
  %a YCrCb senza perdita.
  Si può quindi operare una riduzione della risoluzione dedicata ai due piani 
  colore Cr e Cb senza visibili peggioramenti della qualità.

%-------------------------------------------------------------------------------
%       SECTION 3
%-------------------------------------------------------------------------------

\section{Compressione video}

La compressione di dati assume un ruolo fondamentale nella trasmissione o 
memorizzazione di sequenze video: citando l'introduzione è assolutamente 
impensabile non comprimere uno \emph{stream} a 1080p, che occupa circa 187MB 
per secondo di video. In seguito verranno descritti i principi base che 
governano tutti gli algoritmi di compressione d'immagini in sequenza.

%-----------------------------------
%       SUBSECTION 1
%-----------------------------------

\subsection{Ridondanza spaziale}

Sfrutta il fatto che ogni fotogramma (\emph{frame}) del video, preso
singolarmente, può essere compresso: valgono infatti tutte le teorie della 
compressione di immagini trattate nel capitolo precedente.
La sola ridondanza spaziale non è però sufficiente a garantire una buona 
dimensione del video compresso, a meno ovviamente di non rinunciare a parecchia 
qualità.

%-----------------------------------
%       SUBSECTION 2
%-----------------------------------

\subsection{Ridondanza temporale}

La vera differenza tra un algoritmo di compressione di immagini ed uno video 
sta nel fatto che il secondo sfrutta la ridondanza temporale dei \emph{frame}. 
Essendo infatti il video nient'altro che una serie di immagini dal  
campionamento uniforme e relativamente frequente (il minor \emph{framerate} 
possibile affinché 
l'occhio abbia la 
percezione del movimento è di $24$ immagini al secondo), si sfrutta il fatto 
che 
tra due \emph{frame} %per evitare ripetizioni
 ``vicini'' vi sia una grande correlazione temporale. 
Infatti solitamente, a meno di situazioni particolari (come un cambio di scena 
o un movimento brusco), in due \emph{frame} adiacenti vi sono gli stessi oggetti
al più spostati di poco rispetto alla loro posizione originale.
\\ \\ %per uniformare
Questa intuizione permette di andare molto oltre il classico $10\%$ della mera 
compressione basata su ridondanza spaziale arrivando ad addirittura allo 
$0.39\%$\footnote{Utilizzando un video di risoluzione 4k ($3996\times2160$ 
pixel), H.265 genera un \emph{bit-rate} di circa $3$ MB/s contro i circa $777$ 
della versione non compressa.} del file video originale. 

%-----------------------------------
%       SUBSECTION 3
%-----------------------------------

%\subsection{Principali algoritmi}