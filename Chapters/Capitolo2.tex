% Chapter Template

\chapter{Calcolatori e dati} % Main chapter title

\label{Chapter2} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Capitolo 2. \emph{Calcolatori e dati}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

Negli ultimi due secoli il concetto di ``calcolatore'', a cui è subentrato nel
lessico comune il termine \emph{computer}, si è ampiamente esteso. Nei primi
anni del XIX secolo vennero poste le basi concettuali del computer programmabile, 
il primo modernamente definibile Turing-completo, da parte di Charles Babbage 
(non a caso considerato il padre del computer\citep{CBabbage})
e negli anni '30 del XX secolo proprio Alan Turing definì i principi del odierno computer. 
\\
Il calcolatore, dunque, passa dall'essere uno strumento usato per
eseguire semplici calcoli matematici (in questa categoria potrebbe rientrare
anche un abaco) a macchina capace di eseguire calcoli matematici anche molto 
complessi (a cui ci si riferisce talvolta con il termine \emph{elaboratore}).
\\
// Aggiungere

%-------------------------------------------------------------------------------
%	SECTION 1
%-------------------------------------------------------------------------------

\section{Acquisizione ed elaborazione dei dati}

Affinché un computer possa eseguire dei calcoli è necessario che disponga di
\emph{dati} su cui effettuarli. L'acquisizione di questi ultimi può avvenire
in diversi modi, con o senza l'intervento di un essere umano.
Nel secondo caso i dati vengono spesso ottenuti grazie alla trasduzione 
di parametri fisici, acquisiti da sensori, in segnali elettrici, successivamente
tradotti da un convertitore analogico-digitale in modo da ottenere valori che 
possano essere compresi da un calcolatore binario.
\\ \\
In entrambi i casi è raro che un'acquisizione sia fine a sé stessa e venga
semplicemente memorizzata dentro ad un supporto digitale: che sia ricavata una
banale statistica o vengano effettuati trasformazioni e calcoli più complessi,
è necessario che i dati vengano elaborati. \\
Un'elaborazione può preservare la struttura originaria di un dato (come avviene
quando si utilizza quest'ultimo come risorsa per effettuare un calcolo) o
modificarla in modo reversibile o irreversibile (rispettivamente in caso, ad
esempio, di una compressione senza o con perdita). 
\\ \\
Qualunque sia il tipo di elaborazione che deve essere svolta è quasi sempre
indispensabile poterla effetture entro certi limiti temporali, sia per
volontà personale di ottenere dei risultati in tempo breve, sia per
necessità imposta dal lavoro che si sta svolgendo (riportando l'esempio fornito
nell'introduzione, in caso si debba effettuare una codifica video in tempo reale
risulta inacettabile farlo a meno di 24 fotogrammi al secondo); un fattore di
grande importanza nell'elaborazione dei dati risiede dunque anche nella potenza
di calcolo di cui si dispone per svolgerla.
%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Potenza di calcolo}
// Far presente che la ``potenza di calcolo'' dipende anche da quali sono le \\
// necessità di chi ne usufruisce \\
La potenza di calcolo di un computer non è una misura che può essere effettuata
in maniera assoluta, ma può essere ottenuta, con approssimazione, come il 
risultato della sovrapposizione di diversi fattori:\\
// Riorganizzare l'indice
\begin{itemize}
\item Potenza \emph{grezza} del processore (MIPS, MFLOPS)
\item Latenza degli accessi in memoria
\item Latenza delle interfacce I/O
\item Bandwidth
\item Throughput
\end{itemize}


// Qui ci vuole dell'altro

Gordon Moore predisse nel 1965\citep{GMoore} che, 
per almeno dieci anni, il numero di transistor in un circuito integrato 
sarebbe raddoppiato ogni anno (a parità di costo di produzione del circuito).
 Nel 1975 stimò, per la decade successiva, un periodo di due anni come 
necessario per ottenere lo stesso incremento. Quest'ultima affermazione, 
nota come ``Legge di Moore'', sebbene abbia mostrato alcuni segni di
cedimento negli ultimi anni\citep{MooresLaw}, ha 
predetto correttamente l'andamento dello sviluppo tecnologico degli ultimi
cinquant'anni; una sempre maggiore \emph{densità} di transistor a parità
di costo ha portato ad un conseguente aumento della capacità di calcolo 
disponibile (più transistor significano più unità logiche e matematiche,
più memoria, più interfacce I/O, etc.), rendendo possibili elaborazioni
sempre più complesse.

// Passare dalla legge di Moore al parallelismo: perché ad un certo \\
// punto è servito mettere più \emph{core} sullo stesso \emph{die}?

A metà del 2005 si era giunti ad un punto in cui non era più possibile 
aumentare la potenza di calcolo di un processore semplicemente introducendo
più transistor e incrementando la frequenza di lavoro: sebbene Intel avesse 
dichiarato possibile raggiungere frequenze pari a 10GHz, dovette presto 
ricredersi quando, raggiunti i 3.8GHz con il Pentium 4 670, si verificarono 
fenomeni di dispersione di potenza nei transistor ad un ulteriore aumento della 
frequenza, con un processo produttivo di 90nm.
Questo, e le temperature raggiunte da così tanti transistor che operano a 
frequenze così elevate, ha reso necessario un cambio di mentalità, facendo 
passare da una ``corsa al GHz'' a un inclusione di più processori (che 
prendono il nome di \emph{core}) sullo stesso \emph{die}. 
Le configurazioni \emph{multi core} hanno permesso che continuasse il 
\emph{trend} dell'incremento della potenza in concomitanza con il crescere 
del numero dei transistor, introducendo però una grande complicazione nella 
progettazione di un software che volesse sfruttare questo parallelismo.
È infatti necessario prestare particolari accorgimenti nella realizzazione 
di codici parallelizzati, in quanto è molto probabile, se non si presta la 
dovuta attenzione, creare situazioni di \emph{race condition}, in cui due (o 
più) \emph{thread} devono accedere e modificare la stessa risorsa globale; 
senza una sincronizzazione o la definizione di una operazione mutuamente 
esclusiva, il comportamento dei due \emph{thread} non è prevedibile a priori. 
Ad esempio, se entrambi cercassero di accedere alla stessa variabile per 
incrementarla, a seconda dell'ordine in cui verranno eseguite queste operazioni 
cambierà il risultato ottenuto:
\begin{table}[htbp]
  \centering
  \subfloat[Comportamento corretto \label{tab:corretto}]
  {
    \centering
    \begin{tabular}{c|c|c|c}
      \multicolumn{1}{c|}{\textbf{Thread 1}}  	&
      \multicolumn{1}{c|}{\textbf{Thread 2}}  	&
      \multicolumn{1}{c|}{}			&
      \multicolumn{1}{c} {\textbf{Valore}}	\\
      \hline
      Read value     &                & $\leftarrow $ & 0 \\
      Increase value &                &               & 0 \\
      Write back     &                & $\rightarrow$ & 1 \\
                     & Read value     & $\leftarrow $ & 1 \\
                     & Increase value &               & 1 \\
                     & Write back     & $\rightarrow$ & 2 \\
    \end{tabular}
  }\qquad\qquad 
  \subfloat[Comportamento non corretto \label{tab:non_corretto}]
  {
    \centering
    \begin{tabular}{c|c|c|c}
      \multicolumn{1}{c|}{\textbf{Thread 1}}  	&
      \multicolumn{1}{c|}{\textbf{Thread 2}}  	&
      \multicolumn{1}{c|}{}			&
      \multicolumn{1}{c} {\textbf{Valore}}	\\
      \hline
      Read value     &                & $\leftarrow $  & 0 \\
                     & Read value     & $\leftarrow $  & 0 \\
      Increase value &                &                & 0 \\
                     & Increase value &                & 0 \\
      Write back     &                & $\rightarrow$  & 1 \\
                     & Write back     & $\rightarrow$  & 1 \\
    \end{tabular}
  }
\end{table}
%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\subsection{Ottimizzazione di algoritmi}

// Potrebbe essere utile introdurre un esempio: perché è stato necessario \\
// elaborare un algoritmo per il calcolo rapido della trasformata discreta di \\
// Fourier?
